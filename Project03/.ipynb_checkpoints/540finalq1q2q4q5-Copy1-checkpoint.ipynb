{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca6945c7-8b9d-4657-9bb4-499bc719c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis, kstest, norm, t\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "os.chdir(\"/Users/kakifang/Documents/duke/fintech540/FinTech545_Spring2025/Projects/Final_Project\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "556fdd55-54eb-4356-a833-e87d8b1ab9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1\n",
    "# Load and preprocess data\n",
    "portfolio_holdings = pd.read_csv(\"initial_portfolio.csv\")\n",
    "price_data = pd.read_csv(\"DailyPrices.csv\", parse_dates=[\"Date\"]).set_index(\"Date\")\n",
    "risk_free_rates = pd.read_csv(\"rf.csv\", parse_dates=[\"Date\"]).set_index(\"Date\")\n",
    "\n",
    "# Calculate daily returns and merge with risk-free rates\n",
    "asset_returns = price_data.pct_change().dropna()\n",
    "asset_returns = asset_returns.reset_index().merge(risk_free_rates, on=\"Date\", how=\"left\").set_index(\"Date\")\n",
    "asset_returns[\"rf\"] = asset_returns[\"rf\"].ffill()\n",
    "asset_returns.sort_index(inplace=True)\n",
    "\n",
    "# Split data into estimation and holding periods\n",
    "estimation_period = asset_returns[asset_returns.index.year <= 2023]\n",
    "evaluation_period = asset_returns[asset_returns.index.year > 2023]\n",
    "\n",
    "# Set market benchmark and calculate excess returns\n",
    "benchmark_ticker = \"SPY\"\n",
    "benchmark_excess_returns_est = estimation_period[benchmark_ticker] - estimation_period[\"rf\"]\n",
    "benchmark_excess_returns_eval = evaluation_period[benchmark_ticker] - evaluation_period[\"rf\"]\n",
    "\n",
    "# Get last price of 2023 for initial weights calculation\n",
    "closing_prices_2023 = price_data[price_data.index <= \"2023-12-31\"]\n",
    "end_of_period_prices = closing_prices_2023.iloc[-1]\n",
    "\n",
    "# Initialize storage for results\n",
    "portfolio_groups = portfolio_holdings[\"Portfolio\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bf64237-53f0-44ab-8fc1-465e435f8fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_capm_parameters(portfolio_groups, portfolio_holdings, estimation_period, benchmark_ticker, benchmark_excess_returns_est):\n",
    "    \"\"\"Calculate CAPM parameters (alpha, beta) for each symbol in each portfolio\"\"\"\n",
    "    capm_results_by_portfolio = {}\n",
    "    \n",
    "    for group_id in portfolio_groups:\n",
    "        portfolio_subset = portfolio_holdings[portfolio_holdings[\"Portfolio\"] == group_id]\n",
    "        symbols = portfolio_subset[\"Symbol\"].tolist()\n",
    "        capm_results = {}\n",
    "        \n",
    "        for symbol in symbols:\n",
    "            if symbol == benchmark_ticker:\n",
    "                continue\n",
    "            excess_returns = estimation_period[symbol] - estimation_period[\"rf\"]\n",
    "            market_excess = benchmark_excess_returns_est\n",
    "            valid_data_mask = (~excess_returns.isna()) & (~market_excess.isna())\n",
    "            \n",
    "            if valid_data_mask.sum() < 2:  # Skip if not enough data\n",
    "                capm_results[symbol] = (0.0, 0.0)\n",
    "                continue\n",
    "                \n",
    "            x_values = market_excess[valid_data_mask].values.reshape(-1, 1)\n",
    "            y_values = excess_returns[valid_data_mask].values\n",
    "            regression = LinearRegression().fit(x_values, y_values)\n",
    "            capm_results[symbol] = (float(regression.intercept_), float(regression.coef_[0]))  # alpha, beta\n",
    "            \n",
    "        capm_results_by_portfolio[str(group_id)] = capm_results\n",
    "    \n",
    "    return capm_results_by_portfolio\n",
    "\n",
    "# Step 1: Calculate CAPM parameters\n",
    "capm_results_by_portfolio = calculate_capm_parameters(portfolio_groups, portfolio_holdings, estimation_period, \n",
    "                                                  benchmark_ticker, benchmark_excess_returns_est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d636076c-cb96-42d5-a13f-8e961b89fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_portfolio_returns(portfolio_groups, portfolio_holdings, evaluation_period, end_of_period_prices):\n",
    "    \"\"\"Calculate portfolio returns and dynamic weights over the holding period\"\"\"\n",
    "    initial_portfolio_weights = {}\n",
    "    daily_weights_by_portfolio = {}\n",
    "    portfolio_returns_by_group = {}\n",
    "    \n",
    "    for group_id in portfolio_groups:\n",
    "        group_id_str = str(group_id)\n",
    "        portfolio_subset = portfolio_holdings[portfolio_holdings[\"Portfolio\"] == group_id]\n",
    "        symbols = portfolio_subset[\"Symbol\"].tolist()\n",
    "        shares = portfolio_subset[\"Holding\"].values\n",
    "        \n",
    "        # Calculate initial weights\n",
    "        market_values = shares * end_of_period_prices[symbols].values\n",
    "        total_value = market_values.sum()\n",
    "        \n",
    "        if np.isclose(total_value, 0):\n",
    "            weights = np.ones(len(symbols)) / len(symbols) if len(symbols) > 0 else np.array([])\n",
    "        else:\n",
    "            weights = market_values / total_value\n",
    "            \n",
    "        initial_portfolio_weights[group_id_str] = {\"weights\": dict(zip(symbols, weights)), \"total_value\": total_value}\n",
    "        \n",
    "        # Track dynamic weights and returns\n",
    "        current_weights = weights.copy()\n",
    "        group_returns = []\n",
    "        historical_weights = []\n",
    "        \n",
    "        for date in evaluation_period.index:\n",
    "            daily_returns = evaluation_period.loc[date, symbols].values\n",
    "            daily_returns[np.isnan(daily_returns)] = 0.0\n",
    "            \n",
    "            # Calculate portfolio return for the day\n",
    "            portfolio_daily_return = np.sum(current_weights * daily_returns)\n",
    "            group_returns.append(portfolio_daily_return)\n",
    "            historical_weights.append(current_weights.copy())\n",
    "            \n",
    "            # Update weights based on returns\n",
    "            updated_values = current_weights * (1 + daily_returns)\n",
    "            updated_total = np.sum(updated_values)\n",
    "            current_weights = np.zeros(len(symbols)) if np.isclose(updated_total, 0) else updated_values / updated_total\n",
    "        \n",
    "        # Store results\n",
    "        daily_weights_by_portfolio[group_id_str] = pd.DataFrame(historical_weights, columns=symbols, index=evaluation_period.index)\n",
    "        portfolio_returns_by_group[group_id_str] = pd.Series(group_returns, index=evaluation_period.index)\n",
    "    \n",
    "    return initial_portfolio_weights, daily_weights_by_portfolio, portfolio_returns_by_group\n",
    "\n",
    "\n",
    "# Step 2: Calculate portfolio returns and weights\n",
    "initial_portfolio_weights, daily_weights_by_portfolio, portfolio_returns_by_group = calculate_portfolio_returns(\n",
    "    portfolio_groups, portfolio_holdings, evaluation_period, end_of_period_prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b86ff71-df4b-488a-ae4f-3f10f56eb374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A':                  WFC       ETN      AMZN      QCOM       LMT        KO  \\\n",
       " Date                                                                     \n",
       " 2024-01-02  0.023048  0.024155  0.023657  0.030724  0.031591  0.031983   \n",
       " 2024-01-03  0.023115  0.023979  0.023360  0.029811  0.031814  0.032489   \n",
       " 2024-01-04  0.023013  0.023605  0.023338  0.029511  0.032307  0.032854   \n",
       " 2024-01-05  0.023305  0.023753  0.022733  0.029215  0.032231  0.032756   \n",
       " 2024-01-08  0.023521  0.023704  0.022754  0.029227  0.032017  0.032587   \n",
       " ...              ...       ...       ...       ...       ...       ...   \n",
       " 2024-12-27  0.030224  0.030268  0.030978  0.030093  0.030520  0.030436   \n",
       " 2024-12-30  0.030152  0.029977  0.030734  0.030050  0.030662  0.030583   \n",
       " 2024-12-31  0.030219  0.030138  0.030768  0.029902  0.030681  0.030747   \n",
       " 2025-01-02  0.030123  0.030069  0.030479  0.029693  0.030820  0.030838   \n",
       " 2025-01-03  0.030061  0.030036  0.030553  0.029657  0.030544  0.030588   \n",
       " \n",
       "                  JNJ      ISRG       XOM       MDT  ...       NOW       TMO  \\\n",
       " Date                                                ...                       \n",
       " 2024-01-02  0.036804  0.021696  0.031014  0.033995  ...  0.023913  0.034042   \n",
       " 2024-01-03  0.037589  0.021300  0.031774  0.034209  ...  0.023287  0.034924   \n",
       " 2024-01-04  0.038160  0.020915  0.032325  0.034662  ...  0.023076  0.034241   \n",
       " 2024-01-05  0.038092  0.020996  0.032055  0.034979  ...  0.022967  0.034806   \n",
       " 2024-01-08  0.038071  0.020869  0.032034  0.035116  ...  0.023029  0.034283   \n",
       " ...              ...       ...       ...       ...  ...       ...       ...   \n",
       " 2024-12-27  0.030658  0.030366  0.029690  0.030254  ...  0.032600  0.029709   \n",
       " 2024-12-30  0.030752  0.030346  0.029888  0.030137  ...  0.032293  0.029847   \n",
       " 2024-12-31  0.030760  0.030262  0.030048  0.030077  ...  0.032271  0.029796   \n",
       " 2025-01-02  0.031011  0.029952  0.030538  0.030156  ...  0.032017  0.029852   \n",
       " 2025-01-03  0.030841  0.030030  0.030423  0.030244  ...  0.031800  0.029946   \n",
       " \n",
       "                  CVX      ANET      NVDA        GE      GILD        MU  \\\n",
       " Date                                                                     \n",
       " 2024-01-02  0.033738  0.017537  0.011730  0.020208  0.029241  0.032502   \n",
       " 2024-01-03  0.033834  0.017255  0.011417  0.019956  0.030067  0.031381   \n",
       " 2024-01-04  0.034785  0.017246  0.011375  0.019831  0.030421  0.031629   \n",
       " 2024-01-05  0.034416  0.017339  0.011482  0.019934  0.030796  0.031813   \n",
       " 2024-01-08  0.034230  0.017302  0.011702  0.020120  0.030259  0.031980   \n",
       " ...              ...       ...       ...       ...       ...       ...   \n",
       " 2024-12-27  0.029467  0.029980  0.029053  0.030077  0.031083  0.030065   \n",
       " 2024-12-30  0.029669  0.029701  0.028638  0.029964  0.031193  0.029867   \n",
       " 2024-12-31  0.029837  0.029643  0.029089  0.029977  0.030869  0.029137   \n",
       " 2025-01-02  0.030183  0.029376  0.028390  0.029720  0.030966  0.028722   \n",
       " 2025-01-03  0.030532  0.029671  0.029201  0.030000  0.030760  0.029763   \n",
       " \n",
       "                CMCSA       DIS  \n",
       " Date                            \n",
       " 2024-01-02  0.038760  0.027560  \n",
       " 2024-01-03  0.038886  0.027708  \n",
       " 2024-01-04  0.038907  0.028244  \n",
       " 2024-01-05  0.038310  0.027918  \n",
       " 2024-01-08  0.038536  0.027920  \n",
       " ...              ...       ...  \n",
       " 2024-12-27  0.030519  0.030379  \n",
       " 2024-12-30  0.030467  0.030312  \n",
       " 2024-12-31  0.030400  0.030475  \n",
       " 2025-01-02  0.030490  0.030603  \n",
       " 2025-01-03  0.030360  0.030416  \n",
       " \n",
       " [254 rows x 33 columns],\n",
       " 'B':                  AXP       HON      META      NFLX       PGR       LLY  \\\n",
       " Date                                                                     \n",
       " 2024-01-02  0.022354  0.033054  0.021340  0.020799  0.023664  0.026846   \n",
       " 2024-01-03  0.022518  0.033012  0.020921  0.020056  0.024064  0.027332   \n",
       " 2024-01-04  0.022422  0.032512  0.020944  0.020260  0.024448  0.028690   \n",
       " 2024-01-05  0.022602  0.032584  0.021114  0.020458  0.024433  0.028553   \n",
       " 2024-01-08  0.022816  0.032340  0.021391  0.020416  0.024370  0.028718   \n",
       " ...              ...       ...       ...       ...       ...       ...   \n",
       " 2024-12-27  0.030069  0.030426  0.029910  0.032339  0.029785  0.030105   \n",
       " 2024-12-30  0.029995  0.030337  0.029952  0.031990  0.029734  0.029906   \n",
       " 2024-12-31  0.029978  0.030310  0.029876  0.032118  0.029912  0.029902   \n",
       " 2025-01-02  0.029927  0.030218  0.029589  0.031796  0.029916  0.029834   \n",
       " 2025-01-03  0.030122  0.030198  0.030313  0.031663  0.030076  0.030099   \n",
       " \n",
       "                  JPM      VRTX       TJX      EQIX  ...      ADBE       ACN  \\\n",
       " Date                                                ...                       \n",
       " 2024-01-02  0.024840  0.036212  0.027755  0.031057  ...  0.050972  0.035654   \n",
       " 2024-01-03  0.025182  0.036648  0.027657  0.031319  ...  0.049665  0.035323   \n",
       " 2024-01-04  0.025232  0.036863  0.027362  0.030975  ...  0.049268  0.034626   \n",
       " 2024-01-05  0.025410  0.037367  0.027695  0.030925  ...  0.048880  0.034555   \n",
       " 2024-01-08  0.025517  0.037368  0.027354  0.030648  ...  0.048629  0.034479   \n",
       " ...              ...       ...       ...       ...  ...       ...       ...   \n",
       " 2024-12-27  0.029779  0.029937  0.030621  0.030422  ...  0.031505  0.030480   \n",
       " 2024-12-30  0.029753  0.030017  0.030581  0.030458  ...  0.031475  0.030341   \n",
       " 2024-12-31  0.029877  0.029676  0.030234  0.030602  ...  0.031803  0.030385   \n",
       " 2025-01-02  0.029929  0.029928  0.030167  0.030832  ...  0.031726  0.030327   \n",
       " 2025-01-03  0.029995  0.030185  0.030282  0.030907  ...  0.031495  0.030101   \n",
       " \n",
       "                 AMGN       LIN         V       WMT      AMAT       CAT  \\\n",
       " Date                                                                     \n",
       " 2024-01-02  0.039125  0.036112  0.030411  0.020704  0.034430  0.029007   \n",
       " 2024-01-03  0.040484  0.036089  0.030302  0.020964  0.032864  0.028777   \n",
       " 2024-01-04  0.041194  0.036242  0.030390  0.021099  0.032447  0.028128   \n",
       " 2024-01-05  0.041551  0.036246  0.030595  0.020903  0.032002  0.028318   \n",
       " 2024-01-08  0.041494  0.036264  0.030580  0.020748  0.031910  0.028575   \n",
       " ...              ...       ...       ...       ...       ...       ...   \n",
       " 2024-12-27  0.029931  0.030934  0.030882  0.030305  0.029316  0.029976   \n",
       " 2024-12-30  0.030088  0.031061  0.030889  0.030155  0.029402  0.030008   \n",
       " 2024-12-31  0.030059  0.031037  0.030929  0.030152  0.029185  0.030213   \n",
       " 2025-01-02  0.030217  0.031115  0.031003  0.030081  0.029007  0.030195   \n",
       " 2025-01-03  0.030090  0.030811  0.030873  0.029995  0.029257  0.029976   \n",
       " \n",
       "                  RTX       UNP  \n",
       " Date                            \n",
       " 2024-01-02  0.025891  0.037640  \n",
       " 2024-01-03  0.026279  0.037383  \n",
       " 2024-01-04  0.026568  0.037354  \n",
       " 2024-01-05  0.026516  0.037271  \n",
       " 2024-01-08  0.026486  0.037063  \n",
       " ...              ...       ...  \n",
       " 2024-12-27  0.030034  0.029540  \n",
       " 2024-12-30  0.030168  0.029717  \n",
       " 2024-12-31  0.030139  0.029792  \n",
       " 2025-01-02  0.030272  0.029827  \n",
       " 2025-01-03  0.030378  0.029999  \n",
       " \n",
       " [254 rows x 33 columns],\n",
       " 'C':                  IBM       TXN       ADP      GOOG      ORCL       BSX  \\\n",
       " Date                                                                     \n",
       " 2024-01-02  0.027348  0.033446  0.029817  0.027813  0.023743  0.024196   \n",
       " 2024-01-03  0.027180  0.033426  0.030069  0.027722  0.023587  0.024366   \n",
       " 2024-01-04  0.027168  0.033201  0.030199  0.028111  0.023417  0.024466   \n",
       " 2024-01-05  0.027336  0.032796  0.030392  0.027687  0.023480  0.024744   \n",
       " 2024-01-08  0.027051  0.032926  0.030598  0.027560  0.023515  0.024742   \n",
       " ...              ...       ...       ...       ...       ...       ...   \n",
       " 2024-12-27  0.029638  0.029662  0.029804  0.029928  0.030003  0.029344   \n",
       " 2024-12-30  0.029666  0.029886  0.030009  0.029771  0.029836  0.029394   \n",
       " 2024-12-31  0.029683  0.029737  0.030042  0.029921  0.029830  0.029428   \n",
       " 2025-01-02  0.029743  0.029782  0.030135  0.029688  0.029899  0.029424   \n",
       " 2025-01-03  0.029860  0.029796  0.029921  0.029820  0.029892  0.029546   \n",
       " \n",
       "                  UNH      TMUS       SYK        GS  ...       KKR      COST  \\\n",
       " Date                                                ...                       \n",
       " 2024-01-02  0.038742  0.027851  0.031048  0.025461  ...  0.020615  0.029429   \n",
       " 2024-01-03  0.039947  0.028308  0.030913  0.025795  ...  0.020363  0.029197   \n",
       " 2024-01-04  0.040478  0.028572  0.030928  0.025572  ...  0.020173  0.029169   \n",
       " 2024-01-05  0.040791  0.028653  0.031405  0.025687  ...  0.020220  0.029377   \n",
       " 2024-01-08  0.040194  0.028845  0.031123  0.025924  ...  0.020554  0.029728   \n",
       " ...              ...       ...       ...       ...  ...       ...       ...   \n",
       " 2024-12-27  0.029288  0.030119  0.029566  0.029973  ...  0.029276  0.032872   \n",
       " 2024-12-30  0.029527  0.030344  0.029688  0.030023  ...  0.029066  0.032644   \n",
       " 2024-12-31  0.029755  0.030385  0.029649  0.030247  ...  0.029129  0.032423   \n",
       " 2025-01-02  0.029758  0.030514  0.029653  0.030317  ...  0.029148  0.032340   \n",
       " 2025-01-03  0.029781  0.030453  0.029645  0.030546  ...  0.029502  0.032223   \n",
       " \n",
       "                  NEE      ABBV      TSLA      MSFT       PEP        CB  \\\n",
       " Date                                                                     \n",
       " 2024-01-02  0.031308  0.031288  0.023214  0.033543  0.041820  0.031672   \n",
       " 2024-01-03  0.031942  0.032476  0.023360  0.033297  0.042853  0.032068   \n",
       " 2024-01-04  0.032426  0.032876  0.022608  0.033548  0.043217  0.032199   \n",
       " 2024-01-05  0.032373  0.033129  0.022591  0.033355  0.042909  0.032373   \n",
       " 2024-01-08  0.032524  0.033272  0.022552  0.033342  0.042282  0.032434   \n",
       " ...              ...       ...       ...       ...       ...       ...   \n",
       " 2024-12-27  0.029234  0.028750  0.032526  0.030124  0.029698  0.030295   \n",
       " 2024-12-30  0.029434  0.028858  0.031240  0.029912  0.030097  0.030546   \n",
       " 2024-12-31  0.029644  0.028909  0.030573  0.029872  0.030227  0.030662   \n",
       " 2025-01-02  0.029732  0.029270  0.029695  0.029754  0.030413  0.030882   \n",
       " 2025-01-03  0.029801  0.029658  0.027986  0.029650  0.030147  0.030564   \n",
       " \n",
       "                 PANW       BLK  \n",
       " Date                            \n",
       " 2024-01-02  0.030855  0.029630  \n",
       " 2024-01-03  0.030428  0.029400  \n",
       " 2024-01-04  0.030420  0.029045  \n",
       " 2024-01-05  0.030127  0.029154  \n",
       " 2024-01-08  0.030091  0.029041  \n",
       " ...              ...       ...  \n",
       " 2024-12-27  0.030242  0.030205  \n",
       " 2024-12-30  0.030182  0.030228  \n",
       " 2024-12-31  0.030222  0.030102  \n",
       " 2025-01-02  0.029971  0.030152  \n",
       " 2025-01-03  0.029873  0.030028  \n",
       " \n",
       " [254 rows x 33 columns],\n",
       " 'Total':                 AAPL      ABBV       ABT       ACN      ADBE       ADI  \\\n",
       " Date                                                                     \n",
       " 2024-01-02  0.009535  0.009920  0.011381  0.011867  0.016966  0.010874   \n",
       " 2024-01-03  0.009221  0.010262  0.011392  0.011768  0.016546  0.010633   \n",
       " 2024-01-04  0.009224  0.010384  0.011447  0.011552  0.016437  0.010460   \n",
       " 2024-01-05  0.009113  0.010456  0.011608  0.011532  0.016313  0.010308   \n",
       " 2024-01-08  0.009063  0.010484  0.011571  0.011499  0.016218  0.010319   \n",
       " ...              ...       ...       ...       ...       ...       ...   \n",
       " 2024-12-27  0.010571  0.009751  0.009969  0.010157  0.010498  0.009959   \n",
       " 2024-12-30  0.010516  0.009766  0.010026  0.010119  0.010497  0.009991   \n",
       " 2024-12-31  0.010502  0.009783  0.009954  0.010135  0.010608  0.009905   \n",
       " 2025-01-02  0.010439  0.009877  0.009992  0.010126  0.010593  0.009911   \n",
       " 2025-01-03  0.010176  0.009984  0.010032  0.010051  0.010516  0.009870   \n",
       " \n",
       "                  ADP      AMAT       AMD      AMGN  ...       TXN      UBER  \\\n",
       " Date                                                ...                       \n",
       " 2024-01-02  0.009454  0.011460  0.014148  0.013023  ...  0.010605  0.011454   \n",
       " 2024-01-03  0.009501  0.010948  0.013341  0.013487  ...  0.010562  0.010893   \n",
       " 2024-01-04  0.009538  0.010826  0.013129  0.013744  ...  0.010486  0.010954   \n",
       " 2024-01-05  0.009592  0.010680  0.013205  0.013867  ...  0.010351  0.010877   \n",
       " 2024-01-08  0.009641  0.010642  0.013435  0.013838  ...  0.010375  0.010820   \n",
       " ...              ...       ...       ...       ...  ...       ...       ...   \n",
       " 2024-12-27  0.010109  0.009769  0.009843  0.009974  ...  0.010060  0.009391   \n",
       " 2024-12-30  0.010155  0.009806  0.009934  0.010035  ...  0.010114  0.009402   \n",
       " 2024-12-31  0.010167  0.009735  0.009833  0.010027  ...  0.010063  0.009460   \n",
       " 2025-01-02  0.010169  0.009685  0.009711  0.010089  ...  0.010050  0.009400   \n",
       " 2025-01-03  0.010073  0.009769  0.009709  0.010047  ...  0.010031  0.009854   \n",
       " \n",
       "                  UNH       UNP         V      VRTX        VZ       WFC  \\\n",
       " Date                                                                     \n",
       " 2024-01-02  0.012284  0.012528  0.010122  0.012053  0.010512  0.008068   \n",
       " 2024-01-03  0.012622  0.012454  0.010095  0.012209  0.010874  0.008111   \n",
       " 2024-01-04  0.012785  0.012463  0.010139  0.012299  0.011038  0.008067   \n",
       " 2024-01-05  0.012874  0.012438  0.010211  0.012471  0.011105  0.008172   \n",
       " 2024-01-08  0.012665  0.012360  0.010198  0.012462  0.011322  0.008266   \n",
       " ...              ...       ...       ...       ...       ...       ...   \n",
       " 2024-12-27  0.009934  0.009843  0.010290  0.009976  0.009746  0.009902   \n",
       " 2024-12-30  0.009992  0.009911  0.010302  0.010011  0.009816  0.009892   \n",
       " 2024-12-31  0.010069  0.009937  0.010317  0.009899  0.009855  0.009913   \n",
       " 2025-01-02  0.010042  0.009959  0.010352  0.009993  0.009963  0.009900   \n",
       " 2025-01-03  0.010026  0.010017  0.010309  0.010079  0.010028  0.009903   \n",
       " \n",
       "                  WMT       XOM  \n",
       " Date                            \n",
       " 2024-01-02  0.006891  0.010857  \n",
       " 2024-01-03  0.006984  0.011149  \n",
       " 2024-01-04  0.007039  0.011331  \n",
       " 2024-01-05  0.006976  0.011240  \n",
       " 2024-01-08  0.006919  0.011257  \n",
       " ...              ...       ...  \n",
       " 2024-12-27  0.010098  0.009727  \n",
       " 2024-12-30  0.010057  0.009805  \n",
       " 2024-12-31  0.010057  0.009857  \n",
       " 2025-01-02  0.010044  0.010036  \n",
       " 2025-01-03  0.010016  0.010023  \n",
       " \n",
       " [254 rows x 99 columns]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weights_by_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22e50999-d9d1-4ae8-9abb-6119aaf43e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Portfolio A Attribution Summary ==========\n",
      "Total Return          : 0.136642\n",
      "  ├─ Systematic Return: 0.189015\n",
      "  └─ Idiosyncratic Ret: -0.052373\n",
      "Total Risk            : 0.007404\n",
      "  ├─ Systematic Risk  : 0.007038\n",
      "  └─ Idiosyncratic Risk: 0.000366\n",
      "\n",
      "========== Portfolio B Attribution Summary ==========\n",
      "Total Return          : 0.203526\n",
      "  ├─ Systematic Return: 0.183015\n",
      "  └─ Idiosyncratic Ret: 0.020511\n",
      "Total Risk            : 0.006854\n",
      "  ├─ Systematic Risk  : 0.006385\n",
      "  └─ Idiosyncratic Risk: 0.000468\n",
      "\n",
      "========== Portfolio C Attribution Summary ==========\n",
      "Total Return          : 0.281172\n",
      "  ├─ Systematic Return: 0.198754\n",
      "  └─ Idiosyncratic Ret: 0.082418\n",
      "Total Risk            : 0.007908\n",
      "  ├─ Systematic Risk  : 0.007206\n",
      "  └─ Idiosyncratic Risk: 0.000702\n",
      "\n",
      "========== Total Portfolio Attribution Summary ==========\n",
      "Total Return          : 0.204731\n",
      "  ├─ Systematic Return: 0.190166\n",
      "  └─ Idiosyncratic Ret: 0.014565\n",
      "Total Risk            : 0.007076\n",
      "  ├─ Systematic Risk  : 0.007183\n",
      "  └─ Idiosyncratic Risk: -0.000108\n",
      "\n",
      "==================================================\n",
      "            RETURN ATTRIBUTION SUMMARY            \n",
      "==================================================\n",
      "Portfolio  Total Return  Systematic Return  Idiosyncratic Return\n",
      "        A      0.136642           0.189015             -0.052373\n",
      "        B      0.203526           0.183015              0.020511\n",
      "        C      0.281172           0.198754              0.082418\n",
      "    Total      0.204731           0.190166              0.014565\n",
      "\n",
      "==================================================\n",
      "             RISK ATTRIBUTION SUMMARY             \n",
      "==================================================\n",
      "Portfolio  Total Risk  Systematic Risk  Idiosyncratic Risk\n",
      "        A    0.007404         0.007038            0.000366\n",
      "        B    0.006854         0.006385            0.000468\n",
      "        C    0.007908         0.007206            0.000702\n",
      "    Total    0.007076         0.007183           -0.000108\n"
     ]
    }
   ],
   "source": [
    "def perform_attribution_analysis(portfolio_groups, portfolio_holdings, evaluation_period, \n",
    "                                 portfolio_returns_by_group, daily_weights_by_portfolio, \n",
    "                                 capm_results_by_portfolio, benchmark_excess_returns_eval):\n",
    "    \"\"\"Perform return and risk attribution analysis for each portfolio + a combined Total.\"\"\"\n",
    "    return_attribution_results = []\n",
    "    risk_attribution_results = []\n",
    "    \n",
    "    # --- per-portfolio loop ---\n",
    "    for group_id in portfolio_groups:\n",
    "        group_id_str = str(group_id)\n",
    "        symbols = portfolio_holdings[portfolio_holdings[\"Portfolio\"]==group_id][\"Symbol\"].tolist()\n",
    "        group_returns = portfolio_returns_by_group[group_id_str]\n",
    "        daily_weights = daily_weights_by_portfolio[group_id_str]\n",
    "\n",
    "        # build series of systematic & idiosyncratic returns\n",
    "        systematic_returns = []\n",
    "        idiosyncratic_returns = []\n",
    "        \n",
    "        for date in evaluation_period.index:\n",
    "            market_return = benchmark_excess_returns_eval.loc[date] if date in benchmark_excess_returns_eval.index else 0.0\n",
    "            current_weights = daily_weights.loc[date].values\n",
    "\n",
    "            # β from your pre-computed CAPM results\n",
    "            betas = [capm_results_by_portfolio[group_id_str].get(sym, (0.0, 0.0))[1] for sym in symbols]\n",
    "            systematic_return_t = np.dot(current_weights, betas) * market_return\n",
    "\n",
    "            total_return_t = group_returns.loc[date]\n",
    "            systematic_returns.append(systematic_return_t)\n",
    "            idiosyncratic_returns.append(total_return_t - systematic_return_t)\n",
    "\n",
    "        systematic_returns = pd.Series(systematic_returns, index=evaluation_period.index)\n",
    "        idiosyncratic_returns = pd.Series(idiosyncratic_returns, index=evaluation_period.index)\n",
    "\n",
    "        # align and mask\n",
    "        valid_data_mask = group_returns.notna() & systematic_returns.notna() & idiosyncratic_returns.notna()\n",
    "        portfolio_total = group_returns[valid_data_mask]\n",
    "        portfolio_systematic = systematic_returns[valid_data_mask]\n",
    "        portfolio_idiosyncratic = idiosyncratic_returns[valid_data_mask]\n",
    "\n",
    "        # Carino attribution\n",
    "        cumulative_return = (1 + portfolio_total).prod() - 1\n",
    "        carino_k = 1.0 if np.isclose(cumulative_return, 0) else np.log1p(cumulative_return) / cumulative_return\n",
    "\n",
    "        carino_k_t = pd.Series(1.0, index=portfolio_total.index)\n",
    "        nonzero_mask = ~np.isclose(portfolio_total, 0)\n",
    "        carino_k_t.loc[nonzero_mask] = np.log1p(portfolio_total[nonzero_mask]) / (portfolio_total[nonzero_mask] * carino_k)\n",
    "\n",
    "        systematic_contribution = (portfolio_systematic * carino_k_t).sum()\n",
    "        idiosyncratic_contribution = (portfolio_idiosyncratic * carino_k_t).sum()\n",
    "\n",
    "        # risk attribution\n",
    "        total_volatility = portfolio_total.std(ddof=0)\n",
    "        systematic_covariance = np.cov(portfolio_systematic, portfolio_total, ddof=0)[0,1] if len(portfolio_total) > 1 else 0\n",
    "        idiosyncratic_covariance = np.cov(portfolio_idiosyncratic, portfolio_total, ddof=0)[0,1] if len(portfolio_total) > 1 else 0\n",
    "\n",
    "        systematic_risk = systematic_covariance / total_volatility if total_volatility and not np.isclose(total_volatility, 0) else 0\n",
    "        idiosyncratic_risk = idiosyncratic_covariance / total_volatility if total_volatility and not np.isclose(total_volatility, 0) else 0\n",
    "\n",
    "        # print & store\n",
    "        print(f\"\\n{'=' * 10} Portfolio {group_id_str} Attribution Summary {'=' * 10}\")\n",
    "        print(f\"Total Return          : {cumulative_return:.6f}\")\n",
    "        print(f\"  ├─ Systematic Return: {systematic_contribution:.6f}\")\n",
    "        print(f\"  └─ Idiosyncratic Ret: {idiosyncratic_contribution:.6f}\")\n",
    "        print(f\"Total Risk            : {total_volatility:.6f}\")\n",
    "        print(f\"  ├─ Systematic Risk  : {systematic_risk:.6f}\")\n",
    "        print(f\"  └─ Idiosyncratic Risk: {idiosyncratic_risk:.6f}\")\n",
    "\n",
    "        return_attribution_results.append({\n",
    "            \"Portfolio\": group_id_str,\n",
    "            \"Total Return\": cumulative_return,\n",
    "            \"Systematic Return\": systematic_contribution,\n",
    "            \"Idiosyncratic Return\": idiosyncratic_contribution\n",
    "        })\n",
    "        risk_attribution_results.append({\n",
    "            \"Portfolio\": group_id_str,\n",
    "            \"Total Risk\": total_volatility,\n",
    "            \"Systematic Risk\": systematic_risk,\n",
    "            \"Idiosyncratic Risk\": idiosyncratic_risk\n",
    "        })\n",
    "\n",
    "    # --- TOTAL PORTFOLIO SECTION ---\n",
    "    # Create a combined portfolio with all holdings\n",
    "    all_portfolios = []\n",
    "    for group_id in portfolio_groups:\n",
    "        portfolio_subset = portfolio_holdings[portfolio_holdings[\"Portfolio\"] == group_id].copy()\n",
    "        all_portfolios.append(portfolio_subset)\n",
    "    \n",
    "    # Combine the portfolios and aggregate by Symbol\n",
    "    combined_portfolio = pd.concat(all_portfolios)\n",
    "    combined_portfolio_agg = combined_portfolio.groupby('Symbol').sum().reset_index()\n",
    "    combined_portfolio_agg['Portfolio'] = 'Total'\n",
    "    \n",
    "    # Create an equivalent portfolio ID and symbols list\n",
    "    total_group_id = 'Total'\n",
    "    total_symbols = combined_portfolio_agg[\"Symbol\"].tolist()\n",
    "    \n",
    "    # Calculate initial weights for total portfolio\n",
    "    total_shares = combined_portfolio_agg[\"Holding\"].values\n",
    "    total_market_values = total_shares * end_of_period_prices[total_symbols].values\n",
    "    total_portfolio_value = total_market_values.sum()\n",
    "    \n",
    "    if np.isclose(total_portfolio_value, 0):\n",
    "        total_weights = np.ones(len(total_symbols)) / len(total_symbols) if len(total_symbols) > 0 else np.array([])\n",
    "    else:\n",
    "        total_weights = total_market_values / total_portfolio_value\n",
    "    \n",
    "    # Calculate CAPM parameters for the total portfolio\n",
    "    total_capm_results = {}\n",
    "    for symbol in total_symbols:\n",
    "        if symbol == benchmark_ticker:\n",
    "            continue\n",
    "        excess_returns = estimation_period[symbol] - estimation_period[\"rf\"]\n",
    "        market_excess = benchmark_excess_returns_est\n",
    "        valid_data_mask = (~excess_returns.isna()) & (~market_excess.isna())\n",
    "        \n",
    "        if valid_data_mask.sum() < 2:  # Skip if not enough data\n",
    "            total_capm_results[symbol] = (0.0, 0.0)\n",
    "            continue\n",
    "            \n",
    "        x_values = market_excess[valid_data_mask].values.reshape(-1, 1)\n",
    "        y_values = excess_returns[valid_data_mask].values\n",
    "        regression = LinearRegression().fit(x_values, y_values)\n",
    "        total_capm_results[symbol] = (float(regression.intercept_), float(regression.coef_[0]))\n",
    "    \n",
    "    # Store CAPM results\n",
    "    capm_results_by_portfolio[total_group_id] = total_capm_results\n",
    "    \n",
    "    # Track dynamic weights and returns for total portfolio\n",
    "    current_total_weights = total_weights.copy()\n",
    "    total_returns = []\n",
    "    total_historical_weights = []\n",
    "    \n",
    "    for date in evaluation_period.index:\n",
    "        daily_returns = evaluation_period.loc[date, total_symbols].values\n",
    "        daily_returns[np.isnan(daily_returns)] = 0.0\n",
    "        \n",
    "        # Calculate portfolio return for the day\n",
    "        total_portfolio_return = np.sum(current_total_weights * daily_returns)\n",
    "        total_returns.append(total_portfolio_return)\n",
    "        total_historical_weights.append(current_total_weights.copy())\n",
    "        \n",
    "        # Update weights based on returns\n",
    "        updated_values = current_total_weights * (1 + daily_returns)\n",
    "        updated_total_value = np.sum(updated_values)\n",
    "        current_total_weights = np.zeros(len(total_symbols)) if np.isclose(updated_total_value, 0) else updated_values / updated_total_value\n",
    "    \n",
    "    # Store results for the total portfolio\n",
    "    daily_weights_by_portfolio[total_group_id] = pd.DataFrame(total_historical_weights, columns=total_symbols, index=evaluation_period.index)\n",
    "    portfolio_returns_by_group[total_group_id] = pd.Series(total_returns, index=evaluation_period.index)\n",
    "    \n",
    "    # Now perform the same attribution analysis on the total portfolio\n",
    "    group_returns = portfolio_returns_by_group[total_group_id]\n",
    "    daily_weights = daily_weights_by_portfolio[total_group_id]\n",
    "    \n",
    "    # build series of systematic & idiosyncratic returns\n",
    "    systematic_returns = []\n",
    "    idiosyncratic_returns = []\n",
    "    \n",
    "    for date in evaluation_period.index:\n",
    "        market_return = benchmark_excess_returns_eval.loc[date] if date in benchmark_excess_returns_eval.index else 0.0\n",
    "        current_weights = daily_weights.loc[date].values\n",
    "\n",
    "        # β from your pre-computed CAPM results for total portfolio\n",
    "        betas = [capm_results_by_portfolio[total_group_id].get(sym, (0.0, 0.0))[1] for sym in total_symbols]\n",
    "        systematic_return_t = np.dot(current_weights, betas) * market_return\n",
    "\n",
    "        total_return_t = group_returns.loc[date]\n",
    "        systematic_returns.append(systematic_return_t)\n",
    "        idiosyncratic_returns.append(total_return_t - systematic_return_t)\n",
    "\n",
    "    systematic_returns = pd.Series(systematic_returns, index=evaluation_period.index)\n",
    "    idiosyncratic_returns = pd.Series(idiosyncratic_returns, index=evaluation_period.index)\n",
    "\n",
    "    # align and mask\n",
    "    valid_data_mask = group_returns.notna() & systematic_returns.notna() & idiosyncratic_returns.notna()\n",
    "    portfolio_total = group_returns[valid_data_mask]\n",
    "    portfolio_systematic = systematic_returns[valid_data_mask]\n",
    "    portfolio_idiosyncratic = idiosyncratic_returns[valid_data_mask]\n",
    "\n",
    "    # Carino attribution\n",
    "    cumulative_return = (1 + portfolio_total).prod() - 1\n",
    "    carino_k = 1.0 if np.isclose(cumulative_return, 0) else np.log1p(cumulative_return) / cumulative_return\n",
    "\n",
    "    carino_k_t = pd.Series(1.0, index=portfolio_total.index)\n",
    "    nonzero_mask = ~np.isclose(portfolio_total, 0)\n",
    "    carino_k_t.loc[nonzero_mask] = np.log1p(portfolio_total[nonzero_mask]) / (portfolio_total[nonzero_mask] * carino_k)\n",
    "\n",
    "    systematic_contribution = (portfolio_systematic * carino_k_t).sum()\n",
    "    idiosyncratic_contribution = (portfolio_idiosyncratic * carino_k_t).sum()\n",
    "\n",
    "    # risk attribution\n",
    "    total_volatility = portfolio_total.std(ddof=0)\n",
    "    systematic_covariance = np.cov(portfolio_systematic, portfolio_total, ddof=0)[0,1] if len(portfolio_total) > 1 else 0\n",
    "    idiosyncratic_covariance = np.cov(portfolio_idiosyncratic, portfolio_total, ddof=0)[0,1] if len(portfolio_total) > 1 else 0\n",
    "\n",
    "    systematic_risk = systematic_covariance / total_volatility if total_volatility and not np.isclose(total_volatility, 0) else 0\n",
    "    idiosyncratic_risk = idiosyncratic_covariance / total_volatility if total_volatility and not np.isclose(total_volatility, 0) else 0\n",
    "\n",
    "    # print & store\n",
    "    print(f\"\\n{'=' * 10} Total Portfolio Attribution Summary {'=' * 10}\")\n",
    "    print(f\"Total Return          : {cumulative_return:.6f}\")\n",
    "    print(f\"  ├─ Systematic Return: {systematic_contribution:.6f}\")\n",
    "    print(f\"  └─ Idiosyncratic Ret: {idiosyncratic_contribution:.6f}\")\n",
    "    print(f\"Total Risk            : {total_volatility:.6f}\")\n",
    "    print(f\"  ├─ Systematic Risk  : {systematic_risk:.6f}\")\n",
    "    print(f\"  └─ Idiosyncratic Risk: {idiosyncratic_risk:.6f}\")\n",
    "\n",
    "    return_attribution_results.append({\n",
    "        \"Portfolio\": total_group_id,\n",
    "        \"Total Return\": cumulative_return,\n",
    "        \"Systematic Return\": systematic_contribution,\n",
    "        \"Idiosyncratic Return\": idiosyncratic_contribution\n",
    "    })\n",
    "    risk_attribution_results.append({\n",
    "        \"Portfolio\": total_group_id,\n",
    "        \"Total Risk\": total_volatility,\n",
    "        \"Systematic Risk\": systematic_risk,\n",
    "        \"Idiosyncratic Risk\": idiosyncratic_risk\n",
    "    })\n",
    "\n",
    "    # Create final DataFrames with improved styling\n",
    "    return_df = pd.DataFrame(return_attribution_results).round(6)\n",
    "    risk_df = pd.DataFrame(risk_attribution_results).round(6)\n",
    "    \n",
    "    return return_df, risk_df\n",
    "\n",
    "# Step 3: Perform attribution analysis\n",
    "return_df, risk_df = perform_attribution_analysis(portfolio_groups, portfolio_holdings, evaluation_period, \n",
    "                                               portfolio_returns_by_group, daily_weights_by_portfolio, \n",
    "                                               capm_results_by_portfolio, benchmark_excess_returns_eval)\n",
    "\n",
    "# Display final results with improved formatting\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RETURN ATTRIBUTION SUMMARY\".center(50))\n",
    "print(\"=\" * 50)\n",
    "print(return_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RISK ATTRIBUTION SUMMARY\".center(50))\n",
    "print(\"=\" * 50)\n",
    "print(risk_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33711b4f-456a-4869-a18b-38a05a1159e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q2\n",
    "# Load and preprocess data\n",
    "portfolio_holdings = pd.read_csv(\"initial_portfolio.csv\")\n",
    "price_data = pd.read_csv(\"DailyPrices.csv\", parse_dates=[\"Date\"]).set_index(\"Date\")\n",
    "risk_free_rates = pd.read_csv(\"rf.csv\", parse_dates=[\"Date\"]).set_index(\"Date\")\n",
    "\n",
    "# Calculate daily returns and merge with risk-free rates\n",
    "asset_returns = price_data.pct_change().dropna()\n",
    "asset_returns = asset_returns.reset_index().merge(risk_free_rates, on=\"Date\", how=\"left\").set_index(\"Date\")\n",
    "asset_returns[\"rf\"] = asset_returns[\"rf\"].ffill()\n",
    "asset_returns.sort_index(inplace=True)\n",
    "\n",
    "# Split data into estimation and evaluation periods\n",
    "estimation_period = asset_returns[asset_returns.index.year <= 2023]\n",
    "evaluation_period = asset_returns[asset_returns.index.year > 2023]\n",
    "\n",
    "# Set market benchmark and calculate excess returns\n",
    "benchmark_ticker = \"SPY\"\n",
    "benchmark_excess_returns_est = estimation_period[benchmark_ticker] - estimation_period[\"rf\"]\n",
    "benchmark_excess_returns_eval = evaluation_period[benchmark_ticker] - evaluation_period[\"rf\"]\n",
    "\n",
    "# Get last price of 2023 for initial weights calculation\n",
    "closing_prices_2023 = price_data[price_data.index <= \"2023-12-31\"]\n",
    "end_of_period_prices = closing_prices_2023.iloc[-1]\n",
    "\n",
    "# Basic parameters\n",
    "market_excess_avg = benchmark_excess_returns_est.mean()\n",
    "risk_free_rate_avg = estimation_period['rf'].mean()\n",
    "market_variance = benchmark_excess_returns_est.var()\n",
    "portfolio_groups = portfolio_holdings[\"Portfolio\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c30066b4-1235-4fd1-a91a-895d952db2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_capm_parameters(portfolio_groups, portfolio_holdings, estimation_period, \n",
    "                              benchmark_ticker, benchmark_excess_returns_est):\n",
    "    \"\"\"Calculate CAPM parameters (alpha, beta) and idiosyncratic variance for each symbol in each portfolio\"\"\"\n",
    "    capm_results_by_portfolio = {}\n",
    "    residual_variance_by_portfolio = {}\n",
    "\n",
    "    for group_id in portfolio_groups:\n",
    "        group_id_str = str(group_id)\n",
    "        portfolio_subset = portfolio_holdings[portfolio_holdings['Portfolio'] == group_id]\n",
    "        symbols = portfolio_subset['Symbol'].tolist()\n",
    "        \n",
    "        capm_results = {}\n",
    "        residual_variance = {}\n",
    "        \n",
    "        for symbol in symbols:\n",
    "            if symbol == benchmark_ticker:  # Special handling for benchmark\n",
    "                capm_results[symbol], residual_variance[symbol] = (0.0, 1.0), 0.0\n",
    "                continue\n",
    "            \n",
    "            excess_returns = estimation_period[symbol] - estimation_period['rf']\n",
    "            market_excess = benchmark_excess_returns_est\n",
    "            \n",
    "            valid_data_mask = (~excess_returns.isna()) & (~market_excess.isna())\n",
    "            x_values, y_values = market_excess[valid_data_mask].values.reshape(-1, 1), excess_returns[valid_data_mask].values\n",
    "            \n",
    "            regression = LinearRegression().fit(x_values, y_values)\n",
    "            alpha, beta = regression.intercept_, regression.coef_[0]\n",
    "            \n",
    "            residuals = y_values - regression.predict(x_values)\n",
    "            idiosyncratic_variance = np.var(residuals, ddof=0)\n",
    "            \n",
    "            # Store results as (alpha, beta) tuple and idiosyncratic variance\n",
    "            capm_results[symbol], residual_variance[symbol] = (alpha, beta), idiosyncratic_variance\n",
    "        \n",
    "        capm_results_by_portfolio[group_id_str], residual_variance_by_portfolio[group_id_str] = capm_results, residual_variance\n",
    "    \n",
    "    # Create a total portfolio by aggregating all holdings\n",
    "    all_portfolios = []\n",
    "    for group_id in portfolio_groups:\n",
    "        portfolio_subset = portfolio_holdings[portfolio_holdings[\"Portfolio\"] == group_id].copy()\n",
    "        all_portfolios.append(portfolio_subset)\n",
    "    \n",
    "    # Combine the portfolios and aggregate by Symbol\n",
    "    combined_portfolio = pd.concat(all_portfolios)\n",
    "    combined_portfolio_agg = combined_portfolio.groupby('Symbol').sum().reset_index()\n",
    "    total_symbols = combined_portfolio_agg[\"Symbol\"].tolist()\n",
    "    \n",
    "    # Calculate CAPM parameters for total portfolio\n",
    "    total_capm_results = {}\n",
    "    total_residual_variance = {}\n",
    "    \n",
    "    for symbol in total_symbols:\n",
    "        if symbol == benchmark_ticker:  # Special handling for benchmark\n",
    "            total_capm_results[symbol], total_residual_variance[symbol] = (0.0, 1.0), 0.0\n",
    "            continue\n",
    "        \n",
    "        excess_returns = estimation_period[symbol] - estimation_period['rf']\n",
    "        market_excess = benchmark_excess_returns_est\n",
    "        \n",
    "        valid_data_mask = (~excess_returns.isna()) & (~market_excess.isna())\n",
    "        x_values, y_values = market_excess[valid_data_mask].values.reshape(-1, 1), excess_returns[valid_data_mask].values\n",
    "        \n",
    "        regression = LinearRegression().fit(x_values, y_values)\n",
    "        alpha, beta = regression.intercept_, regression.coef_[0]\n",
    "        \n",
    "        residuals = y_values - regression.predict(x_values)\n",
    "        idiosyncratic_variance = np.var(residuals, ddof=0)\n",
    "        \n",
    "        total_capm_results[symbol], total_residual_variance[symbol] = (alpha, beta), idiosyncratic_variance\n",
    "    \n",
    "    # Add total portfolio to results\n",
    "    capm_results_by_portfolio['Total'], residual_variance_by_portfolio['Total'] = total_capm_results, total_residual_variance\n",
    "    \n",
    "    return capm_results_by_portfolio, residual_variance_by_portfolio, combined_portfolio_agg\n",
    "\n",
    "    \n",
    "# Step 1: Calculate CAPM parameters\n",
    "capm_results_by_portfolio, residual_variance_by_portfolio, combined_portfolio_agg = calculate_capm_parameters(\n",
    "    portfolio_groups, portfolio_holdings, estimation_period, benchmark_ticker, benchmark_excess_returns_est\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d9db996-b208-492d-a459-faf9ec6472e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize_portfolios(portfolio_groups, portfolio_holdings, capm_results_by_portfolio, \n",
    "                         residual_variance_by_portfolio, risk_free_rate_avg, market_excess_avg, \n",
    "                         market_variance, combined_portfolio_agg=None):\n",
    "    \"\"\"Optimize each portfolio to maximize Sharpe ratio\"\"\"\n",
    "    optimal_weights_by_portfolio = {}\n",
    "    expected_sharpe_by_portfolio = {}\n",
    "\n",
    "    for group_id in portfolio_groups:\n",
    "        group_id_str = str(group_id)\n",
    "        symbols = portfolio_holdings[portfolio_holdings['Portfolio'] == group_id]['Symbol'].tolist()\n",
    "        asset_count = len(symbols)\n",
    "        \n",
    "        if asset_count == 0:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Get beta values from CAPM results\n",
    "            betas = np.array([capm_results_by_portfolio[group_id_str][symbol][1] for symbol in symbols])  \n",
    "            idiosyncratic_variances = np.array([residual_variance_by_portfolio[group_id_str][symbol] for symbol in symbols])\n",
    "            \n",
    "            # Expected returns using CAPM (assuming alpha=0)\n",
    "            expected_returns = risk_free_rate_avg + betas * market_excess_avg\n",
    "            \n",
    "            # Expected covariance matrix\n",
    "            covariance_matrix = np.outer(betas, betas) * market_variance + np.diag(idiosyncratic_variances)\n",
    "            \n",
    "            # Optimization function: minimize negative Sharpe ratio\n",
    "            def negative_sharpe(weights):\n",
    "                portfolio_return = np.sum(weights * expected_returns)\n",
    "                portfolio_variance = weights.T @ covariance_matrix @ weights\n",
    "                if portfolio_variance <= 1e-12:\n",
    "                    return np.inf\n",
    "                portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "                return -(portfolio_return - risk_free_rate_avg) / portfolio_volatility\n",
    "            \n",
    "            constraints = ({\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1})\n",
    "            bounds = [(-1, 1)] * asset_count\n",
    "            \n",
    "            initial_guess = np.ones(asset_count) / asset_count\n",
    "            expected_sharpe_value = np.nan\n",
    "            \n",
    "            result = minimize(\n",
    "                negative_sharpe, \n",
    "                initial_guess,\n",
    "                method=\"SLSQP\", \n",
    "                bounds=bounds, \n",
    "                constraints=constraints\n",
    "            )\n",
    "            \n",
    "            if result.success:\n",
    "                optimal_weights = result.x\n",
    "                optimal_weights_by_portfolio[group_id_str] = {symbol: weight for symbol, weight in zip(symbols, optimal_weights)}\n",
    "                expected_sharpe_value = -result.fun\n",
    "            else:\n",
    "                print(f\"\\n{'=' * 10} Optimization failed for {group_id}: {result.message} {'=' * 10}\")\n",
    "                optimal_weights_by_portfolio[group_id_str] = {symbol: 1.0/asset_count for symbol in symbols}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\n{'=' * 10} Error {group_id}: {e} {'=' * 10}\")\n",
    "            optimal_weights_by_portfolio[group_id_str] = {symbol: 1.0/asset_count for symbol in symbols}\n",
    "            \n",
    "        expected_sharpe_by_portfolio[group_id_str] = expected_sharpe_value\n",
    "    \n",
    "    # Optimize total portfolio\n",
    "    if combined_portfolio_agg is not None:\n",
    "        total_symbols = combined_portfolio_agg[\"Symbol\"].tolist()\n",
    "        total_asset_count = len(total_symbols)\n",
    "        \n",
    "        if total_asset_count > 0:\n",
    "            try:\n",
    "                # Get betas and idiosyncratic variances for total portfolio\n",
    "                total_betas = np.array([capm_results_by_portfolio['Total'][symbol][1] for symbol in total_symbols])\n",
    "                total_idiosyncratic_variances = np.array([residual_variance_by_portfolio['Total'][symbol] for symbol in total_symbols])\n",
    "                \n",
    "                # Expected returns (CAPM, alpha=0)\n",
    "                total_expected_returns = risk_free_rate_avg + total_betas * market_excess_avg\n",
    "                \n",
    "                # Expected covariance matrix\n",
    "                total_covariance_matrix = np.outer(total_betas, total_betas) * market_variance + np.diag(total_idiosyncratic_variances)\n",
    "                \n",
    "                # Optimization function: minimize negative Sharpe ratio\n",
    "                def total_negative_sharpe(weights):\n",
    "                    portfolio_return = np.sum(weights * total_expected_returns)\n",
    "                    portfolio_variance = weights.T @ total_covariance_matrix @ weights\n",
    "                    if portfolio_variance <= 1e-12:\n",
    "                        return np.inf\n",
    "                    portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "                    return -(portfolio_return - risk_free_rate_avg) / portfolio_volatility\n",
    "                \n",
    "                constraints = ({\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1})\n",
    "                bounds = [(-1, 1)] * total_asset_count\n",
    "                \n",
    "                initial_guess = np.ones(total_asset_count) / total_asset_count\n",
    "                expected_sharpe_value = np.nan\n",
    "                \n",
    "                result = minimize(\n",
    "                    total_negative_sharpe,\n",
    "                    initial_guess,\n",
    "                    method=\"SLSQP\",\n",
    "                    bounds=bounds,\n",
    "                    constraints=constraints\n",
    "                )\n",
    "                \n",
    "                if result.success:\n",
    "                    total_optimal_weights = result.x\n",
    "                    optimal_weights_by_portfolio['Total'] = {symbol: weight for symbol, weight in zip(total_symbols, total_optimal_weights)}\n",
    "                    expected_sharpe_by_portfolio['Total'] = -result.fun\n",
    "                else:\n",
    "                    print(f\"\\n{'=' * 10} Optimization failed for Total portfolio: {result.message} {'=' * 10}\")\n",
    "                    optimal_weights_by_portfolio['Total'] = {symbol: 1.0/total_asset_count for symbol in total_symbols}\n",
    "                    expected_sharpe_by_portfolio['Total'] = np.nan\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"\\n{'=' * 10} Error optimizing Total portfolio: {e} {'=' * 10}\")\n",
    "                optimal_weights_by_portfolio['Total'] = {symbol: 1.0/total_asset_count for symbol in total_symbols}\n",
    "                expected_sharpe_by_portfolio['Total'] = np.nan\n",
    "    \n",
    "    return optimal_weights_by_portfolio, expected_sharpe_by_portfolio\n",
    "\n",
    "# Step 2: Optimize portfolios for maximum Sharpe ratio\n",
    "optimal_weights_by_portfolio, expected_sharpe_by_portfolio = optimize_portfolios(\n",
    "    portfolio_groups, portfolio_holdings, capm_results_by_portfolio, residual_variance_by_portfolio, \n",
    "    risk_free_rate_avg, market_excess_avg, market_variance, combined_portfolio_agg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a32c150a-80d4-4389-a38c-bfec197420dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_optimal_portfolio_returns(portfolio_groups, portfolio_holdings, optimal_weights_by_portfolio, \n",
    "                                        evaluation_period, combined_portfolio_agg=None):\n",
    "    \"\"\"Calculate daily returns and weights for optimal portfolios\"\"\"\n",
    "    optimal_portfolio_returns = {}\n",
    "    optimal_daily_weights = {}\n",
    "\n",
    "    for group_id in portfolio_groups:\n",
    "        group_id_str = str(group_id)\n",
    "        if group_id_str not in optimal_weights_by_portfolio:\n",
    "            continue\n",
    "            \n",
    "        weights_dict = optimal_weights_by_portfolio[group_id_str]\n",
    "        symbols = list(weights_dict.keys())\n",
    "        initial_weights = np.array([weights_dict[symbol] for symbol in symbols])\n",
    "        asset_count = len(symbols)\n",
    "        \n",
    "        if asset_count == 0:\n",
    "            continue\n",
    "        \n",
    "        current_weights = initial_weights.copy()\n",
    "        portfolio_daily_returns = []\n",
    "        historical_weights = []\n",
    "        \n",
    "        for date in evaluation_period.index:\n",
    "            daily_returns = evaluation_period.loc[date, symbols].values\n",
    "            if np.isnan(daily_returns).any():\n",
    "                daily_returns[np.isnan(daily_returns)] = 0.0\n",
    "            \n",
    "            portfolio_return = np.sum(current_weights * daily_returns)\n",
    "            portfolio_daily_returns.append(portfolio_return)\n",
    "            historical_weights.append(current_weights.copy())\n",
    "            \n",
    "            updated_values = current_weights * (1 + daily_returns)\n",
    "            total_value = np.sum(updated_values)\n",
    "            \n",
    "            if np.isclose(total_value, 0):\n",
    "                current_weights = np.zeros(asset_count)\n",
    "            else:\n",
    "                current_weights = updated_values / total_value\n",
    "        \n",
    "        optimal_portfolio_returns[group_id_str] = pd.Series(portfolio_daily_returns, index=evaluation_period.index)\n",
    "        optimal_daily_weights[group_id_str] = pd.DataFrame(historical_weights, columns=symbols, index=evaluation_period.index)\n",
    "    \n",
    "    # Calculate returns for total portfolio\n",
    "    if 'Total' in optimal_weights_by_portfolio and combined_portfolio_agg is not None:\n",
    "        total_weights_dict = optimal_weights_by_portfolio['Total']\n",
    "        total_symbols = list(total_weights_dict.keys())\n",
    "        initial_total_weights = np.array([total_weights_dict[symbol] for symbol in total_symbols])\n",
    "        total_asset_count = len(total_symbols)\n",
    "        \n",
    "        if total_asset_count > 0:\n",
    "            current_total_weights = initial_total_weights.copy()\n",
    "            total_daily_returns = []\n",
    "            total_historical_weights = []\n",
    "            \n",
    "            for date in evaluation_period.index:\n",
    "                daily_returns = evaluation_period.loc[date, total_symbols].values\n",
    "                if np.isnan(daily_returns).any():\n",
    "                    daily_returns[np.isnan(daily_returns)] = 0.0\n",
    "                \n",
    "                total_return = np.sum(current_total_weights * daily_returns)\n",
    "                total_daily_returns.append(total_return)\n",
    "                total_historical_weights.append(current_total_weights.copy())\n",
    "                \n",
    "                updated_values = current_total_weights * (1 + daily_returns)\n",
    "                total_value = np.sum(updated_values)\n",
    "                \n",
    "                if np.isclose(total_value, 0):\n",
    "                    current_total_weights = np.zeros(total_asset_count)\n",
    "                else:\n",
    "                    current_total_weights = updated_values / total_value\n",
    "            \n",
    "            optimal_portfolio_returns['Total'] = pd.Series(total_daily_returns, index=evaluation_period.index)\n",
    "            optimal_daily_weights['Total'] = pd.DataFrame(total_historical_weights, columns=total_symbols, index=evaluation_period.index)\n",
    "    \n",
    "    return optimal_portfolio_returns, optimal_daily_weights\n",
    "\n",
    "# Step 3: Calculate portfolio returns and weights\n",
    "optimal_portfolio_returns, optimal_daily_weights = calculate_optimal_portfolio_returns(\n",
    "    portfolio_groups, portfolio_holdings, optimal_weights_by_portfolio, evaluation_period, combined_portfolio_agg\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7b180c8-5cd3-4991-9146-ee7d1d1dcd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Portfolio A Attribution Summary ==========\n",
      "Total Return          : 0.224619\n",
      "  ├─ Systematic Return: 0.214041\n",
      "  └─ Idiosyncratic Ret: 0.010579\n",
      "Total Risk (Daily)    : 0.008244\n",
      "  ├─ Systematic Risk  : 0.007930\n",
      "  ├─ Idiosyncratic Risk: 0.000314\n",
      "  └─ Expected Idio Risk: 0.002619\n",
      "\n",
      "========== Portfolio B Attribution Summary ==========\n",
      "Total Return          : 0.230978\n",
      "  ├─ Systematic Return: 0.197342\n",
      "  └─ Idiosyncratic Ret: 0.033636\n",
      "Total Risk (Daily)    : 0.007042\n",
      "  ├─ Systematic Risk  : 0.006866\n",
      "  ├─ Idiosyncratic Risk: 0.000176\n",
      "  └─ Expected Idio Risk: 0.002143\n",
      "\n",
      "========== Portfolio C Attribution Summary ==========\n",
      "Total Return          : 0.320950\n",
      "  ├─ Systematic Return: 0.219626\n",
      "  └─ Idiosyncratic Ret: 0.101323\n",
      "Total Risk (Daily)    : 0.008496\n",
      "  ├─ Systematic Risk  : 0.007859\n",
      "  ├─ Idiosyncratic Risk: 0.000637\n",
      "  └─ Expected Idio Risk: 0.002298\n",
      "\n",
      "========== Portfolio Total Attribution Summary ==========\n",
      "Total Return          : 0.261093\n",
      "  ├─ Systematic Return: 0.209468\n",
      "  └─ Idiosyncratic Ret: 0.051625\n",
      "Total Risk (Daily)    : 0.007577\n",
      "  ├─ Systematic Risk  : 0.007791\n",
      "  ├─ Idiosyncratic Risk: -0.000214\n",
      "  └─ Expected Idio Risk: 0.001344\n",
      "\n",
      "==================================================\n",
      "            RETURN ATTRIBUTION SUMMARY            \n",
      "==================================================\n",
      "Portfolio  Total Return  Systematic Return  Idiosyncratic Return\n",
      "        A      0.224619           0.214041              0.010579\n",
      "        B      0.230978           0.197342              0.033636\n",
      "        C      0.320950           0.219626              0.101323\n",
      "    Total      0.261093           0.209468              0.051625\n",
      "\n",
      "==================================================\n",
      "             RISK ATTRIBUTION SUMMARY             \n",
      "==================================================\n",
      "Portfolio  Total Risk  Systematic Risk  Idiosyncratic Risk  Expected Idio Risk\n",
      "        A    0.008244         0.007930            0.000314            0.002619\n",
      "        B    0.007042         0.006866            0.000176            0.002143\n",
      "        C    0.008496         0.007859            0.000637            0.002298\n",
      "    Total    0.007577         0.007791           -0.000214            0.001344\n"
     ]
    }
   ],
   "source": [
    "def perform_attribution_analysis(portfolio_groups, portfolio_holdings, optimal_weights_by_portfolio, \n",
    "                                 optimal_portfolio_returns, optimal_daily_weights, \n",
    "                                 capm_results_by_portfolio, residual_variance_by_portfolio, \n",
    "                                 evaluation_period, benchmark_excess_returns_eval, combined_portfolio_agg=None):\n",
    "    \"\"\"Perform return and risk attribution analysis for each portfolio\"\"\"\n",
    "    return_attribution_results = [] \n",
    "    risk_attribution_results = []\n",
    "\n",
    "    all_portfolios = list(portfolio_groups) + ['Total']\n",
    "    \n",
    "    for group_id in all_portfolios:\n",
    "        group_id_str = str(group_id)\n",
    "        \n",
    "        if group_id == 'Total' and combined_portfolio_agg is not None:\n",
    "            symbols = combined_portfolio_agg[\"Symbol\"].tolist()\n",
    "        else:\n",
    "            symbols = portfolio_holdings[portfolio_holdings['Portfolio'] == group_id]['Symbol'].tolist()\n",
    "        \n",
    "        if group_id_str not in optimal_portfolio_returns:\n",
    "            continue\n",
    "            \n",
    "        portfolio_returns = optimal_portfolio_returns[group_id_str]\n",
    "        daily_weights = optimal_daily_weights[group_id_str]\n",
    "        \n",
    "        # Calculate systematic and idiosyncratic returns\n",
    "        systematic_returns = []\n",
    "        idiosyncratic_returns = []\n",
    "        \n",
    "        for date in evaluation_period.index:\n",
    "            if date not in benchmark_excess_returns_eval.index or pd.isna(benchmark_excess_returns_eval.loc[date]):\n",
    "                market_excess_return = 0.0\n",
    "            else:\n",
    "                market_excess_return = benchmark_excess_returns_eval.loc[date]\n",
    "                \n",
    "            current_weights = daily_weights.loc[date].values\n",
    "            \n",
    "            # Calculate systematic component\n",
    "            systematic_return = 0.0\n",
    "            for i, symbol in enumerate(symbols):\n",
    "                if symbol in capm_results_by_portfolio[group_id_str]:\n",
    "                    beta = capm_results_by_portfolio[group_id_str][symbol][1]\n",
    "                    systematic_return += current_weights[i] * beta * market_excess_return\n",
    "            \n",
    "            # Get total portfolio return for the day\n",
    "            total_return = portfolio_returns.loc[date]\n",
    "            \n",
    "            # Calculate idiosyncratic component\n",
    "            idiosyncratic_return = total_return - systematic_return\n",
    "            \n",
    "            systematic_returns.append(systematic_return)\n",
    "            idiosyncratic_returns.append(idiosyncratic_return)\n",
    "        \n",
    "        # Create Series\n",
    "        systematic_returns = pd.Series(systematic_returns, index=evaluation_period.index)\n",
    "        idiosyncratic_returns = pd.Series(idiosyncratic_returns, index=evaluation_period.index)\n",
    "        \n",
    "        # Handle missing values\n",
    "        valid_data_mask = (~pd.isna(portfolio_returns)) & (~pd.isna(systematic_returns)) & (~pd.isna(idiosyncratic_returns))\n",
    "        portfolio_total = portfolio_returns[valid_data_mask]\n",
    "        portfolio_systematic = systematic_returns[valid_data_mask]\n",
    "        portfolio_idiosyncratic = idiosyncratic_returns[valid_data_mask]\n",
    "        \n",
    "        if len(portfolio_total) == 0:\n",
    "            print(f\"\\n{'=' * 10} Warning: Portfolio {group_id} has no valid data for attribution analysis {'=' * 10}\")\n",
    "            continue\n",
    "        \n",
    "        # Carino return attribution\n",
    "        cumulative_return = (1 + portfolio_total).prod() - 1\n",
    "        \n",
    "        if np.isclose(cumulative_return, 0):\n",
    "            carino_k = 0\n",
    "        else:\n",
    "            carino_k = np.log(1 + cumulative_return) / cumulative_return\n",
    "        \n",
    "        carino_k_t = np.ones_like(portfolio_total)\n",
    "        non_zero_mask = ~np.isclose(portfolio_total, 0)\n",
    "        carino_k_t[non_zero_mask] = np.log1p(portfolio_total[non_zero_mask]) / (portfolio_total[non_zero_mask] * carino_k)\n",
    "        carino_k_t = pd.Series(carino_k_t, index=portfolio_total.index)\n",
    "        \n",
    "        systematic_contribution = (portfolio_systematic * carino_k_t).sum()\n",
    "        idiosyncratic_contribution = (portfolio_idiosyncratic * carino_k_t).sum()\n",
    "        \n",
    "        # Risk attribution (daily basis)\n",
    "        daily_volatility = portfolio_total.std(ddof=0)\n",
    "        \n",
    "        if len(portfolio_total) > 1 and not np.isclose(daily_volatility, 0):\n",
    "            systematic_covariance = np.cov(portfolio_systematic, portfolio_total, ddof=0)[0, 1]\n",
    "            idiosyncratic_covariance = np.cov(portfolio_idiosyncratic, portfolio_total, ddof=0)[0, 1]\n",
    "            \n",
    "            systematic_risk = systematic_covariance / daily_volatility\n",
    "            idiosyncratic_risk = idiosyncratic_covariance / daily_volatility\n",
    "        else:\n",
    "            systematic_risk = 0\n",
    "            idiosyncratic_risk = 0\n",
    "        \n",
    "        # Calculate expected idiosyncratic risk\n",
    "        if group_id == 'Total' and combined_portfolio_agg is not None:\n",
    "            if 'Total' in optimal_weights_by_portfolio:\n",
    "                initial_weights = np.array([optimal_weights_by_portfolio['Total'][symbol] for symbol in symbols])\n",
    "                idiosyncratic_variances = np.array([residual_variance_by_portfolio['Total'][symbol] for symbol in symbols])\n",
    "                expected_idiosyncratic_risk = np.sqrt(np.sum(initial_weights**2 * idiosyncratic_variances))\n",
    "            else:\n",
    "                expected_idiosyncratic_risk = np.nan\n",
    "        else:\n",
    "            if group_id_str in optimal_weights_by_portfolio:\n",
    "                initial_weights = np.array([optimal_weights_by_portfolio[group_id_str][symbol] for symbol in symbols])\n",
    "                idiosyncratic_variances = np.array([residual_variance_by_portfolio[group_id_str][symbol] for symbol in symbols])\n",
    "                expected_idiosyncratic_risk = np.sqrt(np.sum(initial_weights**2 * idiosyncratic_variances))\n",
    "            else:\n",
    "                expected_idiosyncratic_risk = np.nan\n",
    "        \n",
    "        # Print attribution results\n",
    "        print(f\"\\n{'=' * 10} Portfolio {group_id_str} Attribution Summary {'=' * 10}\")\n",
    "        print(f\"Total Return          : {cumulative_return:.6f}\")\n",
    "        print(f\"  ├─ Systematic Return: {systematic_contribution:.6f}\")\n",
    "        print(f\"  └─ Idiosyncratic Ret: {idiosyncratic_contribution:.6f}\")\n",
    "        print(f\"Total Risk (Daily)    : {daily_volatility:.6f}\")\n",
    "        print(f\"  ├─ Systematic Risk  : {systematic_risk:.6f}\")\n",
    "        print(f\"  ├─ Idiosyncratic Risk: {idiosyncratic_risk:.6f}\")\n",
    "        print(f\"  └─ Expected Idio Risk: {expected_idiosyncratic_risk:.6f}\")\n",
    "        \n",
    "        # Store results\n",
    "        return_attribution_results.append({\n",
    "            \"Portfolio\": group_id,\n",
    "            \"Total Return\": cumulative_return,\n",
    "            \"Systematic Return\": systematic_contribution,\n",
    "            \"Idiosyncratic Return\": idiosyncratic_contribution\n",
    "        })\n",
    "        \n",
    "        risk_attribution_results.append({\n",
    "            \"Portfolio\": group_id,\n",
    "            \"Total Risk\": daily_volatility,\n",
    "            \"Systematic Risk\": systematic_risk,\n",
    "            \"Idiosyncratic Risk\": idiosyncratic_risk,\n",
    "            \"Expected Idio Risk\": expected_idiosyncratic_risk\n",
    "        })\n",
    "    \n",
    "    return return_attribution_results, risk_attribution_results\n",
    "\n",
    "# Step 4: Perform attribution analysis\n",
    "return_attribution_results, risk_attribution_results = perform_attribution_analysis(\n",
    "    portfolio_groups, portfolio_holdings, optimal_weights_by_portfolio, optimal_portfolio_returns, \n",
    "    optimal_daily_weights, capm_results_by_portfolio, residual_variance_by_portfolio, \n",
    "    evaluation_period, benchmark_excess_returns_eval, combined_portfolio_agg\n",
    ")\n",
    "\n",
    "# Display final results with improved formatting\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RETURN ATTRIBUTION SUMMARY\".center(50))\n",
    "print(\"=\" * 50)\n",
    "return_df = pd.DataFrame(return_attribution_results).round(6)\n",
    "print(return_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RISK ATTRIBUTION SUMMARY\".center(50))\n",
    "print(\"=\" * 50)\n",
    "risk_df = pd.DataFrame(risk_attribution_results).round(6)\n",
    "print(risk_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b37b3592-54ce-4c55-bd99-ea9e137c71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q4\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import inspect\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Set constants\n",
    "RISK_THRESHOLD = 0.05\n",
    "MONTE_CARLO_ITERATIONS = 100000\n",
    "np.random.seed(21)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def ingest_market_data():\n",
    "    # Import and structure financial data for analysis\n",
    "    portfolio_holdings = pd.read_csv('initial_portfolio.csv')\n",
    "    price_data = pd.read_csv('DailyPrices.csv', parse_dates=['Date'])\n",
    "    risk_free_rates = pd.read_csv('rf.csv', parse_dates=['Date'])\n",
    "    \n",
    "    price_data.set_index('Date', inplace=True)\n",
    "    risk_free_rates.set_index('Date', inplace=True)\n",
    "    \n",
    "    asset_returns = price_data.pct_change()\n",
    "    \n",
    "    asset_returns = asset_returns.reset_index()\n",
    "    risk_free_rates = risk_free_rates.reset_index()\n",
    "    returns_merged = pd.merge_asof(asset_returns.sort_values('Date'),\n",
    "                                   risk_free_rates.sort_values('Date'),\n",
    "                                   on='Date',\n",
    "                                   direction='backward')\n",
    "    returns_merged.set_index('Date', inplace=True)\n",
    "    returns_merged['rf'] = returns_merged['rf'].ffill()\n",
    "    \n",
    "    asset_returns = returns_merged.dropna(subset=returns_merged.columns.difference(['rf']))\n",
    "    asset_returns = returns_merged.dropna(subset=['rf'])\n",
    "    \n",
    "    estimation_period = asset_returns[asset_returns.index.year <= 2023].copy()\n",
    "    estimation_returns = estimation_period.drop(columns=['rf'], errors='ignore')\n",
    "    \n",
    "    investable_universe = portfolio_holdings['Symbol'].unique().tolist()\n",
    "    investable_universe = [ticker for ticker in investable_universe if ticker in estimation_returns.columns]\n",
    "    \n",
    "    return portfolio_holdings, price_data, asset_returns, estimation_returns, investable_universe\n",
    "\n",
    "portfolio_holdings, price_data, asset_returns, estimation_returns, investable_universe = ingest_market_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df876ba1-f615-4089-894d-a1fc8356441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "         DISTRIBUTION SELECTION ANALYSIS          \n",
      "==================================================\n",
      "  WFC: Selected model = Gen T (AICc=-1320.37), Parameters=[5.0037e+00 1.0000e-03 1.3700e-02]\n",
      "  ETN: Selected model = Gen T (AICc=-1353.58), Parameters=[3.8783e+00 2.4000e-03 1.2000e-02]\n",
      "  AMZN: Selected model = Gen T (AICc=-1232.15), Parameters=[5.9219e+00 2.2000e-03 1.6900e-02]\n",
      "  QCOM: Selected model = Gen T (AICc=-1259.42), Parameters=[5.2207e+00 1.4000e-03 1.5600e-02]\n",
      "  LMT: Selected model = Gen T (AICc=-1589.31), Parameters=[ 3.7033e+00 -2.0000e-04  7.4000e-03]\n",
      "  KO: Selected model = Gen T (AICc=-1690.34), Parameters=[5.2155e+00 1.0000e-04 6.6000e-03]\n",
      "  JNJ: Selected model = Gen T (AICc=-1611.97), Parameters=[ 3.605 -0.     0.007]\n",
      "  ISRG: Selected model = Gen T (AICc=-1311.49), Parameters=[4.7002e+00 1.5000e-03 1.3700e-02]\n",
      "  XOM: Selected model = Gen T (AICc=-1363.94), Parameters=[ 7.8807e+00 -2.0000e-04  1.3600e-02]\n",
      "  MDT: Selected model = Gen T (AICc=-1448.71), Parameters=[4.583e+00 5.000e-04 1.040e-02]\n",
      "  DHR: Selected model = Gen T (AICc=-1395.12), Parameters=[5.3055e+00 5.0000e-04 1.1900e-02]\n",
      "  PLD: Selected model = Gen T (AICc=-1337.94), Parameters=[6.6757e+00 9.0000e-04 1.3900e-02]\n",
      "  BA: Selected model = Gen T (AICc=-1335.71), Parameters=[4.703e+00 1.300e-03 1.310e-02]\n",
      "  PG: Selected model = Gen T (AICc=-1625.03), Parameters=[5.5198 0.     0.0076]\n",
      "  MRK: Selected model = Gen T (AICc=-1501.28), Parameters=[8.0684e+00 2.0000e-04 1.0300e-02]\n",
      "  AMD: Selected model = Gen T (AICc=-1062.75), Parameters=[4.6975e+00 2.6000e-03 2.2600e-02]\n",
      "  BX: Selected model = Gen T (AICc=-1200.40), Parameters=[6.3059e+00 2.8000e-03 1.8200e-02]\n",
      "  PM: Selected model = Gen T (AICc=-1570.04), Parameters=[8.1562e+00 1.0000e-04 9.0000e-03]\n",
      "  SCHW: Selected model = Gen T (AICc=-1164.07), Parameters=[ 2.8391e+00 -2.0000e-04  1.5900e-02]\n",
      "  VZ: Selected model = Gen T (AICc=-1465.94), Parameters=[3.2712e+00 3.0000e-04 9.1000e-03]\n",
      "  COP: Selected model = Gen T (AICc=-1307.26), Parameters=[5.8301e+00 2.0000e-04 1.4500e-02]\n",
      "  ADI: Selected model = Gen T (AICc=-1348.73), Parameters=[6.3639e+00 9.0000e-04 1.3500e-02]\n",
      "  BAC: Selected model = Gen T (AICc=-1338.24), Parameters=[ 4.2675e+00 -1.0000e-04  1.2700e-02]\n",
      "  NOW: Selected model = NIG (AICc=-1259.27), Parameters=[ 0.969  -0.2251  0.0072  0.0191]\n",
      "  TMO: Selected model = Gen T (AICc=-1415.77), Parameters=[ 5.1609e+00 -1.0000e-04  1.1400e-02]\n",
      "  CVX: Selected model = Gen T (AICc=-1418.55), Parameters=[ 4.5534e+00 -1.0000e-04  1.1000e-02]\n",
      "  ANET: Selected model = Gen T (AICc=-1166.37), Parameters=[2.7441e+00 2.4000e-03 1.5600e-02]\n",
      "  NVDA: Selected model = Gen T (AICc=-1086.71), Parameters=[4.7894e+00 3.6000e-03 2.1700e-02]\n",
      "  GE: Selected model = NIG (AICc=-1381.76), Parameters=[ 6.1882  2.3721 -0.0111  0.0334]\n",
      "  GILD: Selected model = Gen T (AICc=-1464.27), Parameters=[8.5693 0.     0.0112]\n",
      "  MU: Selected model = NIG (AICc=-1194.58), Parameters=[ 1.453   0.5481 -0.0077  0.0248]\n",
      "  CMCSA: Selected model = Gen T (AICc=-1436.12), Parameters=[4.5561e+00 9.0000e-04 1.0600e-02]\n",
      "  DIS: Selected model = Gen T (AICc=-1351.29), Parameters=[4.9084e+00 2.0000e-04 1.2800e-02]\n",
      "  AXP: Selected model = Gen T (AICc=-1367.06), Parameters=[4.7186e+00 1.2000e-03 1.2300e-02]\n",
      "  HON: Selected model = Gen T (AICc=-1526.49), Parameters=[5.7291e+00 4.0000e-04 9.3000e-03]\n",
      "  META: Selected model = Gen T (AICc=-1232.44), Parameters=[4.2196e+00 2.8000e-03 1.5700e-02]\n",
      "  NFLX: Selected model = Gen T (AICc=-1213.49), Parameters=[3.6448e+00 9.0000e-04 1.5600e-02]\n",
      "  PGR: Selected model = Gen T (AICc=-1382.50), Parameters=[2.6468e+00 1.2000e-03 9.9000e-03]\n",
      "  LLY: Selected model = Gen T (AICc=-1359.82), Parameters=[3.2336e+00 1.7000e-03 1.1200e-02]\n",
      "  JPM: Selected model = Gen T (AICc=-1492.30), Parameters=[3.5188e+00 1.6000e-03 8.8000e-03]\n",
      "  VRTX: Selected model = Gen T (AICc=-1429.51), Parameters=[4.007e+00 1.400e-03 1.040e-02]\n",
      "  TJX: Selected model = Gen T (AICc=-1581.97), Parameters=[1.01918e+01 8.00000e-04 9.00000e-03]\n",
      "  EQIX: Selected model = Gen T (AICc=-1383.26), Parameters=[5.2959e+00 1.2000e-03 1.2200e-02]\n",
      "  AAPL: Selected model = Gen T (AICc=-1476.83), Parameters=[7.3271e+00 1.8000e-03 1.0700e-02]\n",
      "  FI: Selected model = Gen T (AICc=-1500.07), Parameters=[3.7216e+00 9.0000e-04 8.9000e-03]\n",
      "  DE: Selected model = Gen T (AICc=-1331.63), Parameters=[5.6007e+00 3.0000e-04 1.3700e-02]\n",
      "  SBUX: Selected model = Gen T (AICc=-1475.53), Parameters=[ 4.1894 -0.      0.0096]\n",
      "  GOOGL: Selected model = Gen T (AICc=-1288.52), Parameters=[4.42e+00 1.70e-03 1.42e-02]\n",
      "  T: Selected model = Gen T (AICc=-1403.47), Parameters=[3.0215e+00 1.0000e-04 1.0000e-02]\n",
      "  ABT: Selected model = Gen T (AICc=-1500.32), Parameters=[ 6.2274e+00 -1.0000e-04  1.0000e-02]\n",
      "  BMY: Selected model = Gen T (AICc=-1509.94), Parameters=[ 4.3598e+00 -1.0000e-03  9.1000e-03]\n",
      "  MS: Selected model = Gen T (AICc=-1362.51), Parameters=[4.4944e+00 4.0000e-04 1.2300e-02]\n",
      "  CRM: Selected model = Gen T (AICc=-1307.08), Parameters=[5.1072e+00 2.0000e-03 1.4100e-02]\n",
      "  PFE: Selected model = Gen T (AICc=-1425.10), Parameters=[ 4.0926e+00 -1.9000e-03  1.0600e-02]\n",
      "  SPGI: Selected model = Gen T (AICc=-1458.78), Parameters=[4.165e+00 1.700e-03 9.900e-03]\n",
      "  BRK-B: Selected model = Gen T (AICc=-1665.17), Parameters=[6.7452e+00 7.0000e-04 7.2000e-03]\n",
      "  ADBE: Selected model = Gen T (AICc=-1247.71), Parameters=[5.878e+00 2.600e-03 1.640e-02]\n",
      "  ACN: Selected model = Gen T (AICc=-1436.65), Parameters=[6.9722e+00 1.2000e-03 1.1500e-02]\n",
      "  AMGN: Selected model = NIG (AICc=-1460.98), Parameters=[ 1.6814  0.4403 -0.0038  0.0162]\n",
      "  LIN: Selected model = Gen T (AICc=-1506.97), Parameters=[3.1728e+00 1.4000e-03 8.3000e-03]\n",
      "  V: Selected model = Gen T (AICc=-1594.58), Parameters=[9.5197e+00 1.0000e-03 8.7000e-03]\n",
      "  WMT: Selected model = Gen T (AICc=-1643.38), Parameters=[6.0451e+00 1.0000e-03 7.4000e-03]\n",
      "  AMAT: Selected model = NIG (AICc=-1207.28), Parameters=[ 3.2925  0.6624 -0.0054  0.0376]\n",
      "  CAT: Selected model = Gen T (AICc=-1325.01), Parameters=[4.4501e+00 9.0000e-04 1.3200e-02]\n",
      "  RTX: Selected model = Gen T (AICc=-1463.20), Parameters=[ 3.2087e+00 -4.0000e-04  9.1000e-03]\n",
      "  UNP: Selected model = Gen T (AICc=-1452.47), Parameters=[3.9853e+00 3.0000e-04 9.9000e-03]\n",
      "  IBM: Selected model = Gen T (AICc=-1609.99), Parameters=[4.8152e+00 1.0000e-03 7.6000e-03]\n",
      "  TXN: Selected model = Gen T (AICc=-1380.48), Parameters=[9.151e+00 2.000e-04 1.340e-02]\n",
      "  ADP: Selected model = Gen T (AICc=-1505.13), Parameters=[3.3903e+00 6.0000e-04 8.5000e-03]\n",
      "  GOOG: Selected model = Gen T (AICc=-1282.97), Parameters=[4.5936e+00 1.8000e-03 1.4500e-02]\n",
      "  ORCL: Selected model = Gen T (AICc=-1369.34), Parameters=[3.0819e+00 2.1000e-03 1.0800e-02]\n",
      "  BSX: Selected model = Gen T (AICc=-1504.18), Parameters=[3.5409e+00 1.0000e-03 8.7000e-03]\n",
      "  UNH: Selected model = Gen T (AICc=-1495.37), Parameters=[3.371e+00 2.000e-04 8.700e-03]\n",
      "  TMUS: Selected model = NIG (AICc=-1512.37), Parameters=[ 1.7178 -0.3805  0.0041  0.0149]\n",
      "  SYK: Selected model = NIG (AICc=-1451.54), Parameters=[ 0.3856 -0.0186  0.0014  0.0092]\n",
      "  GS: Selected model = Gen T (AICc=-1387.44), Parameters=[5.5056e+00 9.0000e-04 1.2200e-02]\n",
      "  UBER: Selected model = Gen T (AICc=-1178.97), Parameters=[9.4406e+00 3.5000e-03 2.0100e-02]\n",
      "  AVGO: Selected model = NIG (AICc=-1272.83), Parameters=[ 1.6296  0.6646 -0.0067  0.0221]\n",
      "  MMC: Selected model = NIG (AICc=-1575.92), Parameters=[ 1.5424 -0.3798  0.0038  0.0124]\n",
      "  CSCO: Selected model = Gen T (AICc=-1528.48), Parameters=[3.8949e+00 1.1000e-03 8.5000e-03]\n",
      "  PLTR: Selected model = NIG (AICc=-904.22), Parameters=[ 0.601   0.1637 -0.0041  0.0318]\n",
      "  MA: Selected model = Gen T (AICc=-1559.65), Parameters=[6.4682e+00 1.0000e-03 8.9000e-03]\n",
      "  C: Selected model = Gen T (AICc=-1370.79), Parameters=[4.168e+00 7.000e-04 1.180e-02]\n",
      "  BKNG: Selected model = Gen T (AICc=-1366.92), Parameters=[8.1204e+00 2.1000e-03 1.3500e-02]\n",
      "  MCD: Selected model = Normal (AICc=-1648.37), Parameters=[0.     0.0088]\n",
      "  LOW: Selected model = NIG (AICc=-1403.99), Parameters=[ 0.8962  0.1124 -0.0011  0.0141]\n",
      "  HD: Selected model = Gen T (AICc=-1455.42), Parameters=[4.5351e+00 7.0000e-04 1.0200e-02]\n",
      "  INTU: Selected model = Gen T (AICc=-1290.77), Parameters=[5.5701e+00 2.0000e-03 1.4900e-02]\n",
      "  LRCX: Selected model = NIG (AICc=-1188.17), Parameters=[ 1.6255  0.555  -0.0064  0.0268]\n",
      "  KKR: Selected model = Gen T (AICc=-1244.80), Parameters=[7.2282e+00 2.5000e-03 1.7000e-02]\n",
      "  COST: Selected model = Gen T (AICc=-1518.99), Parameters=[4.6212e+00 1.6000e-03 9.0000e-03]\n",
      "  NEE: Selected model = Gen T (AICc=-1368.54), Parameters=[ 2.9512e+00 -8.0000e-04  1.0700e-02]\n",
      "  ABBV: Selected model = Gen T (AICc=-1522.50), Parameters=[4.0196e+00 4.0000e-04 8.7000e-03]\n",
      "  TSLA: Selected model = Gen T (AICc=-991.99), Parameters=[6.4912e+00 3.2000e-03 2.7800e-02]\n",
      "  MSFT: Selected model = Gen T (AICc=-1360.99), Parameters=[7.7719e+00 1.7000e-03 1.3600e-02]\n",
      "  PEP: Selected model = Gen T (AICc=-1627.61), Parameters=[5.805e+00 1.000e-04 7.600e-03]\n",
      "  CB: Selected model = Gen T (AICc=-1473.85), Parameters=[5.6918e+00 4.0000e-04 1.0300e-02]\n",
      "  PANW: Selected model = Gen T (AICc=-1201.81), Parameters=[3.3221e+00 3.3000e-03 1.5600e-02]\n",
      "  BLK: Selected model = Gen T (AICc=-1423.66), Parameters=[7.9337e+00 5.0000e-04 1.2000e-02]\n"
     ]
    }
   ],
   "source": [
    "def compute_information_criterion(log_likelihood, sample_size, param_count):\n",
    "    # Calculate corrected AIC to evaluate model fit\n",
    "    aic = 2 * param_count - 2 * log_likelihood\n",
    "    aicc = aic + (2 * param_count**2 + 2 * param_count) / (sample_size - param_count - 1)\n",
    "    return aicc\n",
    "\n",
    "def identify_optimal_distributions(estimation_returns, investable_universe):\n",
    "    # Find best statistical distribution for each asset\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"DISTRIBUTION SELECTION ANALYSIS\".center(50))\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Statistical distribution options to evaluate\n",
    "    candidate_distributions = {\n",
    "        'Normal': stats.norm,\n",
    "        'Gen T': stats.t,\n",
    "        'NIG': stats.norminvgauss,\n",
    "        'SkewNorm': stats.skewnorm\n",
    "    }\n",
    "    \n",
    "    optimal_distribution_models = {}\n",
    "    distribution_analysis_results = {}\n",
    "\n",
    "    for ticker in investable_universe:\n",
    "        asset_return_series = estimation_returns[ticker].dropna()\n",
    "        sample_size = len(asset_return_series)\n",
    "\n",
    "        lowest_aicc = np.inf\n",
    "        best_distribution = None\n",
    "        best_parameter_set = None\n",
    "        asset_distribution_results = {}\n",
    "\n",
    "        for dist_name, distribution_function in candidate_distributions.items():\n",
    "            if dist_name in ['Normal', 'SkewNorm']:\n",
    "                parameters = distribution_function.fit(asset_return_series, floc=0)\n",
    "                param_count = len(parameters) - 1  # one parameter fixed\n",
    "            elif dist_name == 'Gen T':\n",
    "                parameters = distribution_function.fit(asset_return_series)\n",
    "                param_count = len(parameters)\n",
    "            else:  # NIG\n",
    "                parameters = distribution_function.fit(asset_return_series)\n",
    "                param_count = len(parameters)\n",
    "\n",
    "            # Calculate log-likelihood\n",
    "            loglikelihood = np.sum(distribution_function.logpdf(asset_return_series, *parameters))\n",
    "                \n",
    "            # Calculate AICc\n",
    "            aicc = compute_information_criterion(loglikelihood, sample_size, param_count)\n",
    "                \n",
    "            asset_distribution_results[dist_name] = {\n",
    "                'parameters': parameters, \n",
    "                'aicc': aicc, \n",
    "                'loglik': loglikelihood, \n",
    "                'param_count': param_count\n",
    "            }\n",
    "\n",
    "            if aicc < lowest_aicc:\n",
    "                lowest_aicc = aicc\n",
    "                best_distribution = dist_name\n",
    "                best_parameter_set = parameters\n",
    "\n",
    "        if best_distribution:\n",
    "            print(f\"  {ticker}: Selected model = {best_distribution} (AICc={lowest_aicc:.2f}), Parameters={np.round(best_parameter_set, 4)}\")\n",
    "            \n",
    "            final_parameters = list(best_parameter_set)\n",
    "            param_names = candidate_distributions[best_distribution].shapes\n",
    "            loc_scale_params = []\n",
    "            \n",
    "            if candidate_distributions[best_distribution].name in stats._continuous_distns._distn_names:\n",
    "                if 'loc' in inspect.signature(candidate_distributions[best_distribution]._parse_args).parameters:\n",
    "                    loc_scale_params.append('loc')\n",
    "                if 'scale' in inspect.signature(candidate_distributions[best_distribution]._parse_args).parameters:\n",
    "                    loc_scale_params.append('scale')\n",
    "\n",
    "            param_indices = {}\n",
    "            current_idx = 0\n",
    "            if param_names:\n",
    "                for p in param_names.split(','):\n",
    "                    param_indices[p.strip()] = current_idx\n",
    "                    current_idx += 1\n",
    "            if 'loc' in loc_scale_params: \n",
    "                param_indices['loc'] = current_idx\n",
    "                current_idx += 1\n",
    "            if 'scale' in loc_scale_params: \n",
    "                param_indices['scale'] = current_idx\n",
    "\n",
    "            if 'loc' in param_indices:\n",
    "                final_parameters[param_indices['loc']] = 0.0\n",
    "\n",
    "            optimal_distribution_models[ticker] = {\n",
    "                'dist_name': best_distribution,\n",
    "                'parameters': tuple(final_parameters),\n",
    "                'distribution_function': candidate_distributions[best_distribution]\n",
    "            }\n",
    "            distribution_analysis_results[ticker] = asset_distribution_results\n",
    "    \n",
    "    return optimal_distribution_models, distribution_analysis_results\n",
    "\n",
    "optimal_distribution_models, distribution_analysis_results = identify_optimal_distributions(estimation_returns, investable_universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61940f88-a0c4-47a8-a3ec-f6cf9e371c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "          PORTFOLIO COMPOSITION ANALYSIS          \n",
      "==================================================\n",
      "  Portfolio A: 33 assets, Market Value: $295444.61\n",
      "  Portfolio B: 33 assets, Market Value: $280904.48\n",
      "  Portfolio C: 33 assets, Market Value: $267591.44\n",
      "  Portfolio Total: 99 assets, Market Value: $843940.53\n"
     ]
    }
   ],
   "source": [
    "def build_quantile_lookup_tables(optimal_distribution_models):\n",
    "    # Create lookup tables for faster sampling\n",
    "    quantile_lookup_tables = {}\n",
    "    precision_points = 1000  # Number of points to precalculate\n",
    "    probability_grid = np.linspace(0.001, 0.999, precision_points)\n",
    "\n",
    "    for ticker in optimal_distribution_models:\n",
    "        model_specs = optimal_distribution_models[ticker]\n",
    "        distribution_function = model_specs['distribution_function']\n",
    "        parameters = model_specs['parameters']\n",
    "        quantile_values = distribution_function.ppf(probability_grid, *parameters)\n",
    "        quantile_lookup_tables[ticker] = {\n",
    "            'probabilities': probability_grid,\n",
    "            'quantile_values': quantile_values\n",
    "        }\n",
    "    \n",
    "    return quantile_lookup_tables\n",
    "\n",
    "quantile_lookup_tables = build_quantile_lookup_tables(optimal_distribution_models)\n",
    "\n",
    "def extract_portfolio_compositions(portfolio_holdings, price_data, optimal_distribution_models):\n",
    "    # Calculate portfolio weights and compositions\n",
    "    portfolio_groups = portfolio_holdings['Portfolio'].unique()\n",
    "    portfolio_compositions = {}\n",
    "    portfolio_asset_weights = {}\n",
    "    portfolio_market_values = {}\n",
    "\n",
    "    # Use reference date for market value calculations\n",
    "    reference_date_prices = price_data.loc[price_data.index <= '2023-12-31'].iloc[-1]\n",
    "\n",
    "    for group_id in portfolio_groups:\n",
    "        portfolio_subset = portfolio_holdings[portfolio_holdings['Portfolio'] == group_id].copy()\n",
    "        portfolio_subset = portfolio_subset[portfolio_subset['Symbol'].isin(optimal_distribution_models.keys())]\n",
    "        portfolio_assets = portfolio_subset['Symbol'].tolist()\n",
    "        share_quantities = portfolio_subset['Holding'].values\n",
    "\n",
    "        portfolio_compositions[str(group_id)] = portfolio_assets\n",
    "\n",
    "        asset_market_values = []\n",
    "        valid_portfolio_assets = []\n",
    "        \n",
    "        for asset, shares in zip(portfolio_assets, share_quantities):\n",
    "            if asset in reference_date_prices.index and not pd.isna(reference_date_prices[asset]):\n",
    "                asset_market_values.append(shares * reference_date_prices[asset])\n",
    "                valid_portfolio_assets.append(asset)\n",
    "\n",
    "        asset_market_values = np.array(asset_market_values)\n",
    "        portfolio_total_value = asset_market_values.sum()\n",
    "        portfolio_market_values[str(group_id)] = portfolio_total_value\n",
    "\n",
    "        if np.isclose(portfolio_total_value, 0):\n",
    "            valid_asset_count = len(valid_portfolio_assets)\n",
    "            asset_weights = np.ones(valid_asset_count) / valid_asset_count if valid_asset_count > 0 else np.array([])\n",
    "            print(f\"  Warning: Portfolio {group_id} has zero market value. Equal weighting applied.\")\n",
    "        else:\n",
    "            asset_weights = asset_market_values / portfolio_total_value\n",
    "\n",
    "        portfolio_asset_weights[str(group_id)] = pd.Series(asset_weights, index=valid_portfolio_assets)\n",
    "        portfolio_compositions[str(group_id)] = valid_portfolio_assets\n",
    "    \n",
    "    # Create aggregate portfolio (Total)\n",
    "    all_portfolios = []\n",
    "    for group_id in portfolio_groups:\n",
    "        portfolio_subset = portfolio_holdings[portfolio_holdings['Portfolio'] == group_id].copy()\n",
    "        all_portfolios.append(portfolio_subset)\n",
    "    \n",
    "    combined_portfolio = pd.concat(all_portfolios)\n",
    "    combined_portfolio_agg = combined_portfolio.groupby('Symbol').sum().reset_index()\n",
    "    \n",
    "    # Filter for assets with distribution models\n",
    "    aggregate_portfolio_assets = [asset for asset in combined_portfolio_agg['Symbol'].tolist() \n",
    "                              if asset in optimal_distribution_models.keys()]\n",
    "    \n",
    "    # Calculate aggregate portfolio weights\n",
    "    aggregate_market_values = []\n",
    "    valid_aggregate_assets = []\n",
    "    \n",
    "    for asset in aggregate_portfolio_assets:\n",
    "        share_quantity = combined_portfolio_agg.loc[combined_portfolio_agg['Symbol'] == asset, 'Holding'].values[0]\n",
    "        if asset in reference_date_prices.index and not pd.isna(reference_date_prices[asset]):\n",
    "            aggregate_market_values.append(share_quantity * reference_date_prices[asset])\n",
    "            valid_aggregate_assets.append(asset)\n",
    "    \n",
    "    aggregate_market_values = np.array(aggregate_market_values)\n",
    "    aggregate_portfolio_value = aggregate_market_values.sum()\n",
    "    portfolio_market_values['Total'] = aggregate_portfolio_value\n",
    "    \n",
    "    if np.isclose(aggregate_portfolio_value, 0):\n",
    "        valid_asset_count = len(valid_aggregate_assets)\n",
    "        aggregate_weights = np.ones(valid_asset_count) / valid_asset_count if valid_asset_count > 0 else np.array([])\n",
    "        print(f\"  Warning: Aggregate portfolio has zero market value. Equal weighting applied.\")\n",
    "    else:\n",
    "        aggregate_weights = aggregate_market_values / aggregate_portfolio_value\n",
    "    \n",
    "    portfolio_asset_weights['Total'] = pd.Series(aggregate_weights, index=valid_aggregate_assets)\n",
    "    portfolio_compositions['Total'] = valid_aggregate_assets\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"PORTFOLIO COMPOSITION ANALYSIS\".center(50))\n",
    "    print(\"=\" * 50)\n",
    "    for portfolio_id, assets in portfolio_compositions.items():\n",
    "        print(f\"  Portfolio {portfolio_id}: {len(assets)} assets, Market Value: ${portfolio_market_values[portfolio_id]:.2f}\")\n",
    "    \n",
    "    return portfolio_compositions, portfolio_asset_weights, portfolio_market_values\n",
    "\n",
    "portfolio_compositions, portfolio_asset_weights, portfolio_market_values = extract_portfolio_compositions(portfolio_holdings, price_data, optimal_distribution_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "426c0a3e-1dad-4a94-9895-71bde73a9e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "   PORTFOLIO RISK ASSESSMENT (95.0% CONFIDENCE)   \n",
      "==================================================\n",
      "\n",
      "========== Portfolio A Risk Analysis ==========\n",
      "  Executing Gaussian Copula simulation with 100000 scenarios...\n",
      "  ├─ Copula Simulation VaR: $4204.28\n",
      "  └─ Copula Simulation ES:  $5553.95\n",
      "  ├─ Parametric VaR:        $4197.97\n",
      "  └─ Parametric ES:         $5264.42\n",
      "  Time elapsed: 0.82 seconds\n",
      "\n",
      "========== Portfolio B Risk Analysis ==========\n",
      "  Executing Gaussian Copula simulation with 100000 scenarios...\n",
      "  ├─ Copula Simulation VaR: $3755.91\n",
      "  └─ Copula Simulation ES:  $4962.67\n",
      "  ├─ Parametric VaR:        $3668.82\n",
      "  └─ Parametric ES:         $4600.85\n",
      "  Time elapsed: 0.51 seconds\n",
      "\n",
      "========== Portfolio C Risk Analysis ==========\n",
      "  Executing Gaussian Copula simulation with 100000 scenarios...\n",
      "  ├─ Copula Simulation VaR: $3724.54\n",
      "  └─ Copula Simulation ES:  $4899.87\n",
      "  ├─ Parametric VaR:        $3684.83\n",
      "  └─ Parametric ES:         $4620.92\n",
      "  Time elapsed: 0.54 seconds\n",
      "\n",
      "========== Portfolio Total Risk Analysis ==========\n",
      "  Executing Gaussian Copula simulation with 100000 scenarios...\n",
      "  ├─ Copula Simulation VaR: $11370.98\n",
      "  └─ Copula Simulation ES:  $14868.69\n",
      "  ├─ Parametric VaR:        $11185.53\n",
      "  └─ Parametric ES:         $14027.11\n",
      "  Time elapsed: 1.99 seconds\n"
     ]
    }
   ],
   "source": [
    "def compute_risk_metrics(simulated_returns, risk_threshold):\n",
    "    # Calculate VaR and Expected Shortfall\n",
    "    if len(simulated_returns) == 0:\n",
    "        return np.nan, np.nan\n",
    "    sorted_returns = np.sort(simulated_returns)\n",
    "    var_index = int(risk_threshold * len(sorted_returns))\n",
    "    value_at_risk = -sorted_returns[var_index]\n",
    "    expected_shortfall = -np.mean(sorted_returns[:var_index+1])\n",
    "    return value_at_risk, expected_shortfall\n",
    "\n",
    "def execute_copula_simulation(assets, weights, asset_returns_history, optimal_distribution_models, \n",
    "                             quantile_lookup_tables, simulation_count, risk_threshold):\n",
    "    # Run Gaussian Copula simulation for risk assessment\n",
    "    asset_count = len(assets)\n",
    "    try:\n",
    "        print(f\"  Executing Gaussian Copula simulation with {simulation_count} scenarios...\")\n",
    "        \n",
    "        # Calculate correlation structure\n",
    "        rank_correlation_matrix = asset_returns_history.corr(method='spearman').fillna(0).values\n",
    "        min_eigenvalue = np.min(np.linalg.eigh(rank_correlation_matrix)[0])\n",
    "        if min_eigenvalue <= 1e-12:\n",
    "            print(f\"  Adjusting correlation matrix for numerical stability.\")\n",
    "            rank_correlation_matrix += np.eye(asset_count) * 1e-10\n",
    "\n",
    "        # Decompose correlation matrix\n",
    "        cholesky_matrix = np.linalg.cholesky(rank_correlation_matrix)\n",
    "\n",
    "        # Generate normal random variables\n",
    "        normal_samples = np.random.randn(simulation_count, asset_count)\n",
    "\n",
    "        # Apply correlation structure\n",
    "        correlated_samples = normal_samples @ cholesky_matrix.T\n",
    "\n",
    "        # Transform to uniform distribution\n",
    "        uniform_samples = stats.norm.cdf(correlated_samples)\n",
    "\n",
    "        # Map to target distributions\n",
    "        return_samples = np.zeros_like(uniform_samples)\n",
    "        for i, asset in enumerate(assets):\n",
    "            if asset in quantile_lookup_tables:\n",
    "                # Fast interpolation from lookup table\n",
    "                lookup_table = quantile_lookup_tables[asset]\n",
    "                return_samples[:, i] = np.interp(uniform_samples[:, i], \n",
    "                                           lookup_table['probabilities'], \n",
    "                                           lookup_table['quantile_values'])\n",
    "            elif asset in optimal_distribution_models:\n",
    "                # Direct calculation\n",
    "                model_specs = optimal_distribution_models[asset]\n",
    "                distribution_function = model_specs['distribution_function']\n",
    "                parameters = model_specs['parameters']\n",
    "                return_samples[:, i] = distribution_function.ppf(uniform_samples[:, i], *parameters)\n",
    "            else:\n",
    "                # Fallback to normal distribution\n",
    "                return_samples[:, i] = stats.norm.ppf(uniform_samples[:, i], loc=0, \n",
    "                                                scale=asset_returns_history[asset].std())\n",
    "\n",
    "        # Handle numerical issues\n",
    "        return_samples[np.isinf(return_samples) | np.isnan(return_samples)] = 0.0\n",
    "\n",
    "        # Calculate portfolio returns\n",
    "        portfolio_return_scenarios = return_samples @ weights\n",
    "\n",
    "        # Calculate risk metrics\n",
    "        var_copula, es_copula = compute_risk_metrics(portfolio_return_scenarios, risk_threshold)\n",
    "        \n",
    "        return var_copula, es_copula\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Copula Simulation Error: {e}\")\n",
    "        return np.nan, np.nan\n",
    "\n",
    "def calculate_parametric_risk_metrics(assets, weights, asset_returns_history, risk_threshold):\n",
    "    # Calculate risk using Multivariate Normal approach\n",
    "    asset_count = len(assets)\n",
    "\n",
    "    # Mean vector (assumed zero for short horizon)\n",
    "    mean_vector = np.zeros(asset_count)\n",
    "\n",
    "    # Estimate covariance structure\n",
    "    if asset_returns_history.shape[0] >= 2:\n",
    "        covariance_matrix = asset_returns_history.cov().fillna(0).values\n",
    "        min_eigenvalue = np.min(np.linalg.eigh(covariance_matrix)[0])\n",
    "        if min_eigenvalue < -1e-12:\n",
    "            print(f\"  Parametric Warning: Covariance matrix not positive semi-definite.\")\n",
    "\n",
    "        # Calculate portfolio moments\n",
    "        portfolio_mean = weights.T @ mean_vector  # Will be 0\n",
    "        portfolio_variance = weights.T @ covariance_matrix @ weights\n",
    "        if portfolio_variance < 0:\n",
    "            print(f\"  Parametric Warning: Negative portfolio variance detected. Setting to 0.\")\n",
    "            portfolio_variance = 0.0\n",
    "\n",
    "        # Calculate portfolio standard deviation\n",
    "        portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "\n",
    "        # Calculate risk metrics using normal distribution formulas\n",
    "        z_score = stats.norm.ppf(risk_threshold)\n",
    "        var_parametric = -(portfolio_mean + z_score * portfolio_volatility)\n",
    "        es_parametric = -(portfolio_mean - portfolio_volatility * stats.norm.pdf(z_score) / risk_threshold)\n",
    "            \n",
    "        return var_parametric, es_parametric\n",
    "\n",
    "\n",
    "def assess_portfolio_risks(portfolio_compositions, portfolio_asset_weights, portfolio_market_values, \n",
    "                          estimation_returns, optimal_distribution_models, quantile_lookup_tables):\n",
    "    # Calculate risk metrics for each portfolio\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"PORTFOLIO RISK ASSESSMENT ({(1-RISK_THRESHOLD)*100}% CONFIDENCE)\".center(50))\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    risk_assessment_results = []\n",
    "\n",
    "    for portfolio_id, assets in portfolio_compositions.items():\n",
    "        start_time = time.time()\n",
    "        print(f\"\\n{'=' * 10} Portfolio {portfolio_id} Risk Analysis {'=' * 10}\")\n",
    "        \n",
    "        if not assets:\n",
    "            print(\"  No assets in this portfolio. Risk assessment skipped.\")\n",
    "            continue\n",
    "\n",
    "        asset_weights = portfolio_asset_weights[portfolio_id]\n",
    "        asset_weights = asset_weights.reindex(assets).fillna(0).values\n",
    "        \n",
    "        if not np.isclose(np.sum(asset_weights), 1.0):\n",
    "            print(f\"  Warning: Portfolio {portfolio_id} weights do not sum to 1. Normalizing.\")\n",
    "            asset_weights /= np.sum(asset_weights)\n",
    "\n",
    "        portfolio_market_value = portfolio_market_values[portfolio_id]\n",
    "        asset_return_history = estimation_returns[assets].dropna()\n",
    "\n",
    "        if asset_return_history.shape[0] < 2 or asset_return_history.shape[1] == 0:\n",
    "            print(f\"  Insufficient data for portfolio {portfolio_id}. Risk assessment skipped.\")\n",
    "            continue\n",
    "\n",
    "        # Execute Gaussian Copula simulation\n",
    "        var_copula, es_copula = execute_copula_simulation(\n",
    "            assets, asset_weights, asset_return_history, optimal_distribution_models, \n",
    "            quantile_lookup_tables, MONTE_CARLO_ITERATIONS, RISK_THRESHOLD\n",
    "        )\n",
    "        \n",
    "        var_dollars_copula = np.nan\n",
    "        es_dollars_copula = np.nan\n",
    "        if not (np.isnan(var_copula) or np.isnan(es_copula)):\n",
    "            var_dollars_copula = var_copula * portfolio_market_value\n",
    "            es_dollars_copula = es_copula * portfolio_market_value\n",
    "            print(f\"  ├─ Copula Simulation VaR: ${var_dollars_copula:.2f}\")\n",
    "            print(f\"  └─ Copula Simulation ES:  ${es_dollars_copula:.2f}\")\n",
    "\n",
    "        # Calculate parametric risk metrics\n",
    "        var_parametric, es_parametric = calculate_parametric_risk_metrics(\n",
    "            assets, asset_weights, asset_return_history, RISK_THRESHOLD\n",
    "        )\n",
    "        \n",
    "        var_dollars_parametric = np.nan\n",
    "        es_dollars_parametric = np.nan\n",
    "        if not (np.isnan(var_parametric) or np.isnan(es_parametric)):\n",
    "            var_dollars_parametric = var_parametric * portfolio_market_value\n",
    "            es_dollars_parametric = es_parametric * portfolio_market_value\n",
    "            print(f\"  ├─ Parametric VaR:        ${var_dollars_parametric:.2f}\")\n",
    "            print(f\"  └─ Parametric ES:         ${es_dollars_parametric:.2f}\")\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"  Time elapsed: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "        risk_assessment_results.append({\n",
    "            'Portfolio': portfolio_id,\n",
    "            'Market Value ($)': portfolio_market_value,\n",
    "            'VaR (Copula) $': var_dollars_copula,\n",
    "            'ES (Copula) $': es_dollars_copula,\n",
    "            'VaR (MVN) $': var_dollars_parametric,\n",
    "            'ES (MVN) $': es_dollars_parametric\n",
    "        })\n",
    "    \n",
    "    return risk_assessment_results\n",
    "\n",
    "risk_assessment_results = assess_portfolio_risks(portfolio_compositions, portfolio_asset_weights, \n",
    "                                              portfolio_market_values, estimation_returns, \n",
    "                                              optimal_distribution_models, quantile_lookup_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4297f33f-fecd-4aef-96dc-272b8d780848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "      COMPREHENSIVE RISK ASSESSMENT SUMMARY       \n",
      "==================================================\n",
      "Portfolio  Market Value ($)  VaR (Copula) $  ES (Copula) $  VaR (MVN) $   ES (MVN) $\n",
      "        A     295444.608200     4204.282450    5553.952915  4197.966533  5264.419394\n",
      "        B     280904.482409     3755.914236    4962.671529  3668.822444  4600.851358\n",
      "        C     267591.439955     3724.535801    4899.868036  3684.828997  4620.924221\n",
      "    Total     843940.530563    11370.975633   14868.689894 11185.530106 14027.106017\n"
     ]
    }
   ],
   "source": [
    "# Display final risk summary\n",
    "risk_summary_df = pd.DataFrame(risk_assessment_results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"COMPREHENSIVE RISK ASSESSMENT SUMMARY\".center(50))\n",
    "print(\"=\" * 50)\n",
    "# Display only dollar values in the report\n",
    "risk_summary_table = risk_summary_df[['Portfolio', 'Market Value ($)', \n",
    "                                      'VaR (Copula) $', 'ES (Copula) $', \n",
    "                                      'VaR (MVN) $', 'ES (MVN) $']]\n",
    "print(risk_summary_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa7a05e2-9837-4515-82f0-88b611993a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q5\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Global parameters\n",
    "ALPHA = 0.05  # 95% confidence level for ES calculation\n",
    "N_SIMULATIONS = 100000\n",
    "np.random.seed(21)\n",
    "\n",
    "def load_data():\n",
    "    # Load and process portfolio, price, and risk-free rate data\n",
    "    initial_portfolio = pd.read_csv('initial_portfolio.csv')\n",
    "    prices = pd.read_csv('DailyPrices.csv', parse_dates=['Date'])\n",
    "    rf = pd.read_csv('rf.csv', parse_dates=['Date'])\n",
    "\n",
    "    prices.set_index('Date', inplace=True)\n",
    "    rf.set_index('Date', inplace=True)\n",
    "\n",
    "    returns = prices.pct_change()\n",
    "\n",
    "    returns = returns.reset_index()\n",
    "    rf = rf.reset_index()\n",
    "    returns_merged = pd.merge_asof(returns.sort_values('Date'),\n",
    "                                   rf.sort_values('Date'),\n",
    "                                   on='Date',\n",
    "                                   direction='backward')\n",
    "    returns_merged.set_index('Date', inplace=True)\n",
    "    returns_merged['rf'] = returns_merged['rf'].ffill()\n",
    "\n",
    "    returns = returns_merged.dropna(subset=returns_merged.columns.difference(['rf']))\n",
    "    returns = returns_merged.dropna(subset=['rf'])\n",
    "\n",
    "    estimation_data = returns[returns.index.year <= 2023].copy()\n",
    "    holding_data = returns[returns.index.year > 2023].copy()\n",
    "    estimation_returns = estimation_data.drop(columns=['rf'], errors='ignore')\n",
    "\n",
    "    all_symbols = initial_portfolio['Symbol'].unique().tolist()\n",
    "    all_symbols = [s for s in all_symbols if s in estimation_returns.columns]\n",
    "\n",
    "    # Get last price of 2023 for initial weights\n",
    "    prices_2023 = prices[prices.index <= \"2023-12-31\"]\n",
    "    last_price = prices_2023.iloc[-1]\n",
    "    \n",
    "    # Set market column\n",
    "    market_col = \"SPY\"\n",
    "    market_returns_est = estimation_data[market_col] - estimation_data[\"rf\"]\n",
    "    market_returns_hold = holding_data[market_col] - holding_data[\"rf\"]\n",
    "    \n",
    "    return (initial_portfolio, prices, returns, estimation_data, holding_data, estimation_returns, \n",
    "            all_symbols, last_price, market_col, market_returns_est, market_returns_hold)\n",
    "\n",
    "# Load the data\n",
    "(initial_portfolio, prices, returns, estimation_data, holding_data, estimation_returns, \n",
    " all_symbols, last_price, market_col, market_returns_est, market_returns_hold) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56ec20eb-528f-4c12-b6cd-c98564ab8e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fitting Distributions to Stock Returns (Estimation Period) ---\n",
      "  WFC: Best fit = Gen T (AICc=-1320.37), Params=[5.0037e+00 1.0000e-03 1.3700e-02]\n",
      "  ETN: Best fit = Gen T (AICc=-1353.58), Params=[3.8783e+00 2.4000e-03 1.2000e-02]\n",
      "  AMZN: Best fit = Gen T (AICc=-1232.15), Params=[5.9219e+00 2.2000e-03 1.6900e-02]\n",
      "  QCOM: Best fit = Gen T (AICc=-1259.42), Params=[5.2207e+00 1.4000e-03 1.5600e-02]\n",
      "  LMT: Best fit = Gen T (AICc=-1589.31), Params=[ 3.7033e+00 -2.0000e-04  7.4000e-03]\n",
      "  KO: Best fit = Gen T (AICc=-1690.34), Params=[5.2155e+00 1.0000e-04 6.6000e-03]\n",
      "  JNJ: Best fit = Gen T (AICc=-1611.97), Params=[ 3.605 -0.     0.007]\n",
      "  ISRG: Best fit = Gen T (AICc=-1311.49), Params=[4.7002e+00 1.5000e-03 1.3700e-02]\n",
      "  XOM: Best fit = Gen T (AICc=-1363.94), Params=[ 7.8807e+00 -2.0000e-04  1.3600e-02]\n",
      "  MDT: Best fit = Gen T (AICc=-1448.71), Params=[4.583e+00 5.000e-04 1.040e-02]\n",
      "  DHR: Best fit = Gen T (AICc=-1395.12), Params=[5.3055e+00 5.0000e-04 1.1900e-02]\n",
      "  PLD: Best fit = Gen T (AICc=-1337.94), Params=[6.6757e+00 9.0000e-04 1.3900e-02]\n",
      "  BA: Best fit = Gen T (AICc=-1335.71), Params=[4.703e+00 1.300e-03 1.310e-02]\n",
      "  PG: Best fit = Gen T (AICc=-1625.03), Params=[5.5198 0.     0.0076]\n",
      "  MRK: Best fit = Gen T (AICc=-1501.28), Params=[8.0684e+00 2.0000e-04 1.0300e-02]\n",
      "  AMD: Best fit = Gen T (AICc=-1062.75), Params=[4.6975e+00 2.6000e-03 2.2600e-02]\n",
      "  BX: Best fit = Gen T (AICc=-1200.40), Params=[6.3059e+00 2.8000e-03 1.8200e-02]\n",
      "  PM: Best fit = Gen T (AICc=-1570.04), Params=[8.1562e+00 1.0000e-04 9.0000e-03]\n",
      "  SCHW: Best fit = Gen T (AICc=-1164.07), Params=[ 2.8391e+00 -2.0000e-04  1.5900e-02]\n",
      "  VZ: Best fit = Gen T (AICc=-1465.94), Params=[3.2712e+00 3.0000e-04 9.1000e-03]\n",
      "  COP: Best fit = Gen T (AICc=-1307.26), Params=[5.8301e+00 2.0000e-04 1.4500e-02]\n",
      "  ADI: Best fit = Gen T (AICc=-1348.73), Params=[6.3639e+00 9.0000e-04 1.3500e-02]\n",
      "  BAC: Best fit = Gen T (AICc=-1338.24), Params=[ 4.2675e+00 -1.0000e-04  1.2700e-02]\n",
      "  NOW: Best fit = NIG (AICc=-1259.27), Params=[ 0.969  -0.2251  0.0072  0.0191]\n",
      "  TMO: Best fit = Gen T (AICc=-1415.77), Params=[ 5.1609e+00 -1.0000e-04  1.1400e-02]\n",
      "  CVX: Best fit = Gen T (AICc=-1418.55), Params=[ 4.5534e+00 -1.0000e-04  1.1000e-02]\n",
      "  ANET: Best fit = Gen T (AICc=-1166.37), Params=[2.7441e+00 2.4000e-03 1.5600e-02]\n",
      "  NVDA: Best fit = Gen T (AICc=-1086.71), Params=[4.7894e+00 3.6000e-03 2.1700e-02]\n",
      "  GE: Best fit = NIG (AICc=-1381.76), Params=[ 6.1882  2.3721 -0.0111  0.0334]\n",
      "  GILD: Best fit = Gen T (AICc=-1464.27), Params=[8.5693 0.     0.0112]\n",
      "  MU: Best fit = NIG (AICc=-1194.58), Params=[ 1.453   0.5481 -0.0077  0.0248]\n",
      "  CMCSA: Best fit = Gen T (AICc=-1436.12), Params=[4.5561e+00 9.0000e-04 1.0600e-02]\n",
      "  DIS: Best fit = Gen T (AICc=-1351.29), Params=[4.9084e+00 2.0000e-04 1.2800e-02]\n",
      "  AXP: Best fit = Gen T (AICc=-1367.06), Params=[4.7186e+00 1.2000e-03 1.2300e-02]\n",
      "  HON: Best fit = Gen T (AICc=-1526.49), Params=[5.7291e+00 4.0000e-04 9.3000e-03]\n",
      "  META: Best fit = Gen T (AICc=-1232.44), Params=[4.2196e+00 2.8000e-03 1.5700e-02]\n",
      "  NFLX: Best fit = Gen T (AICc=-1213.49), Params=[3.6448e+00 9.0000e-04 1.5600e-02]\n",
      "  PGR: Best fit = Gen T (AICc=-1382.50), Params=[2.6468e+00 1.2000e-03 9.9000e-03]\n",
      "  LLY: Best fit = Gen T (AICc=-1359.82), Params=[3.2336e+00 1.7000e-03 1.1200e-02]\n",
      "  JPM: Best fit = Gen T (AICc=-1492.30), Params=[3.5188e+00 1.6000e-03 8.8000e-03]\n",
      "  VRTX: Best fit = Gen T (AICc=-1429.51), Params=[4.007e+00 1.400e-03 1.040e-02]\n",
      "  TJX: Best fit = Gen T (AICc=-1581.97), Params=[1.01918e+01 8.00000e-04 9.00000e-03]\n",
      "  EQIX: Best fit = Gen T (AICc=-1383.26), Params=[5.2959e+00 1.2000e-03 1.2200e-02]\n",
      "  AAPL: Best fit = Gen T (AICc=-1476.83), Params=[7.3271e+00 1.8000e-03 1.0700e-02]\n",
      "  FI: Best fit = Gen T (AICc=-1500.07), Params=[3.7216e+00 9.0000e-04 8.9000e-03]\n",
      "  DE: Best fit = Gen T (AICc=-1331.63), Params=[5.6007e+00 3.0000e-04 1.3700e-02]\n",
      "  SBUX: Best fit = Gen T (AICc=-1475.53), Params=[ 4.1894 -0.      0.0096]\n",
      "  GOOGL: Best fit = Gen T (AICc=-1288.52), Params=[4.42e+00 1.70e-03 1.42e-02]\n",
      "  T: Best fit = Gen T (AICc=-1403.47), Params=[3.0215e+00 1.0000e-04 1.0000e-02]\n",
      "  ABT: Best fit = Gen T (AICc=-1500.32), Params=[ 6.2274e+00 -1.0000e-04  1.0000e-02]\n",
      "  BMY: Best fit = Gen T (AICc=-1509.94), Params=[ 4.3598e+00 -1.0000e-03  9.1000e-03]\n",
      "  MS: Best fit = Gen T (AICc=-1362.51), Params=[4.4944e+00 4.0000e-04 1.2300e-02]\n",
      "  CRM: Best fit = Gen T (AICc=-1307.08), Params=[5.1072e+00 2.0000e-03 1.4100e-02]\n",
      "  PFE: Best fit = Gen T (AICc=-1425.10), Params=[ 4.0926e+00 -1.9000e-03  1.0600e-02]\n",
      "  SPGI: Best fit = Gen T (AICc=-1458.78), Params=[4.165e+00 1.700e-03 9.900e-03]\n",
      "  BRK-B: Best fit = Gen T (AICc=-1665.17), Params=[6.7452e+00 7.0000e-04 7.2000e-03]\n",
      "  ADBE: Best fit = Gen T (AICc=-1247.71), Params=[5.878e+00 2.600e-03 1.640e-02]\n",
      "  ACN: Best fit = Gen T (AICc=-1436.65), Params=[6.9722e+00 1.2000e-03 1.1500e-02]\n",
      "  AMGN: Best fit = NIG (AICc=-1460.98), Params=[ 1.6814  0.4403 -0.0038  0.0162]\n",
      "  LIN: Best fit = Gen T (AICc=-1506.97), Params=[3.1728e+00 1.4000e-03 8.3000e-03]\n",
      "  V: Best fit = Gen T (AICc=-1594.58), Params=[9.5197e+00 1.0000e-03 8.7000e-03]\n",
      "  WMT: Best fit = Gen T (AICc=-1643.38), Params=[6.0451e+00 1.0000e-03 7.4000e-03]\n",
      "  AMAT: Best fit = NIG (AICc=-1207.28), Params=[ 3.2925  0.6624 -0.0054  0.0376]\n",
      "  CAT: Best fit = Gen T (AICc=-1325.01), Params=[4.4501e+00 9.0000e-04 1.3200e-02]\n",
      "  RTX: Best fit = Gen T (AICc=-1463.20), Params=[ 3.2087e+00 -4.0000e-04  9.1000e-03]\n",
      "  UNP: Best fit = Gen T (AICc=-1452.47), Params=[3.9853e+00 3.0000e-04 9.9000e-03]\n",
      "  IBM: Best fit = Gen T (AICc=-1609.99), Params=[4.8152e+00 1.0000e-03 7.6000e-03]\n",
      "  TXN: Best fit = Gen T (AICc=-1380.48), Params=[9.151e+00 2.000e-04 1.340e-02]\n",
      "  ADP: Best fit = Gen T (AICc=-1505.13), Params=[3.3903e+00 6.0000e-04 8.5000e-03]\n",
      "  GOOG: Best fit = Gen T (AICc=-1282.97), Params=[4.5936e+00 1.8000e-03 1.4500e-02]\n",
      "  ORCL: Best fit = Gen T (AICc=-1369.34), Params=[3.0819e+00 2.1000e-03 1.0800e-02]\n",
      "  BSX: Best fit = Gen T (AICc=-1504.18), Params=[3.5409e+00 1.0000e-03 8.7000e-03]\n",
      "  UNH: Best fit = Gen T (AICc=-1495.37), Params=[3.371e+00 2.000e-04 8.700e-03]\n",
      "  TMUS: Best fit = NIG (AICc=-1512.37), Params=[ 1.7178 -0.3805  0.0041  0.0149]\n",
      "  SYK: Best fit = NIG (AICc=-1451.54), Params=[ 0.3856 -0.0186  0.0014  0.0092]\n",
      "  GS: Best fit = Gen T (AICc=-1387.44), Params=[5.5056e+00 9.0000e-04 1.2200e-02]\n",
      "  UBER: Best fit = Gen T (AICc=-1178.97), Params=[9.4406e+00 3.5000e-03 2.0100e-02]\n",
      "  AVGO: Best fit = NIG (AICc=-1272.83), Params=[ 1.6296  0.6646 -0.0067  0.0221]\n",
      "  MMC: Best fit = NIG (AICc=-1575.92), Params=[ 1.5424 -0.3798  0.0038  0.0124]\n",
      "  CSCO: Best fit = Gen T (AICc=-1528.48), Params=[3.8949e+00 1.1000e-03 8.5000e-03]\n",
      "  PLTR: Best fit = NIG (AICc=-904.22), Params=[ 0.601   0.1637 -0.0041  0.0318]\n",
      "  MA: Best fit = Gen T (AICc=-1559.65), Params=[6.4682e+00 1.0000e-03 8.9000e-03]\n",
      "  C: Best fit = Gen T (AICc=-1370.79), Params=[4.168e+00 7.000e-04 1.180e-02]\n",
      "  BKNG: Best fit = Gen T (AICc=-1366.92), Params=[8.1204e+00 2.1000e-03 1.3500e-02]\n",
      "  MCD: Best fit = Normal (AICc=-1648.37), Params=[0.     0.0088]\n",
      "  LOW: Best fit = NIG (AICc=-1403.99), Params=[ 0.8962  0.1124 -0.0011  0.0141]\n",
      "  HD: Best fit = Gen T (AICc=-1455.42), Params=[4.5351e+00 7.0000e-04 1.0200e-02]\n",
      "  INTU: Best fit = Gen T (AICc=-1290.77), Params=[5.5701e+00 2.0000e-03 1.4900e-02]\n",
      "  LRCX: Best fit = NIG (AICc=-1188.17), Params=[ 1.6255  0.555  -0.0064  0.0268]\n",
      "  KKR: Best fit = Gen T (AICc=-1244.80), Params=[7.2282e+00 2.5000e-03 1.7000e-02]\n",
      "  COST: Best fit = Gen T (AICc=-1518.99), Params=[4.6212e+00 1.6000e-03 9.0000e-03]\n",
      "  NEE: Best fit = Gen T (AICc=-1368.54), Params=[ 2.9512e+00 -8.0000e-04  1.0700e-02]\n",
      "  ABBV: Best fit = Gen T (AICc=-1522.50), Params=[4.0196e+00 4.0000e-04 8.7000e-03]\n",
      "  TSLA: Best fit = Gen T (AICc=-991.99), Params=[6.4912e+00 3.2000e-03 2.7800e-02]\n",
      "  MSFT: Best fit = Gen T (AICc=-1360.99), Params=[7.7719e+00 1.7000e-03 1.3600e-02]\n",
      "  PEP: Best fit = Gen T (AICc=-1627.61), Params=[5.805e+00 1.000e-04 7.600e-03]\n",
      "  CB: Best fit = Gen T (AICc=-1473.85), Params=[5.6918e+00 4.0000e-04 1.0300e-02]\n",
      "  PANW: Best fit = Gen T (AICc=-1201.81), Params=[3.3221e+00 3.3000e-03 1.5600e-02]\n",
      "  BLK: Best fit = Gen T (AICc=-1423.66), Params=[7.9337e+00 5.0000e-04 1.2000e-02]\n"
     ]
    }
   ],
   "source": [
    "def calculate_aicc(log_likelihood, n, k):\n",
    "    # Calculate corrected AIC\n",
    "    aic = 2 * k - 2 * log_likelihood\n",
    "    aicc = aic + (2 * k**2 + 2 * k) / (n - k - 1)\n",
    "    return aicc\n",
    "\n",
    "def fit_distributions(estimation_returns, all_symbols):\n",
    "    # Find best distribution model for each stock's returns\n",
    "    print(\"\\n--- Fitting Distributions to Stock Returns (Estimation Period) ---\")\n",
    "    \n",
    "    # distributions to fit\n",
    "    dist_options = {\n",
    "        'Normal': stats.norm,\n",
    "        'Gen T': stats.t,\n",
    "        'NIG': stats.norminvgauss,\n",
    "        'SkewNorm': stats.skewnorm\n",
    "    }\n",
    "    \n",
    "    best_fit_models = {}\n",
    "    fitting_results = {}\n",
    "\n",
    "    for symbol in all_symbols:\n",
    "        data = estimation_returns[symbol].dropna()\n",
    "        n = len(data)\n",
    "\n",
    "        best_aicc = np.inf\n",
    "        best_name = None\n",
    "        best_params = None\n",
    "        results_per_stock = {}\n",
    "\n",
    "        for name, dist in dist_options.items():\n",
    "            try:\n",
    "                if name in ['Normal', 'SkewNorm']:\n",
    "                    params = dist.fit(data, floc=0)\n",
    "                    k = len(params) - 1  # one parameter fixed\n",
    "                elif name == 'Gen T':\n",
    "                    params = dist.fit(data)\n",
    "                    k = len(params)\n",
    "                else:  # NIG\n",
    "                    params = dist.fit(data)\n",
    "                    k = len(params)\n",
    "\n",
    "                # log-likelihood\n",
    "                loglikelihood = np.sum(dist.logpdf(data, *params))\n",
    "                    \n",
    "                # AICc\n",
    "                aicc = calculate_aicc(loglikelihood, n, k)\n",
    "                    \n",
    "                results_per_stock[name] = {'params': params, 'aicc': aicc, 'loglik': loglikelihood, 'k': k}\n",
    "\n",
    "                if aicc < best_aicc:\n",
    "                    best_aicc = aicc\n",
    "                    best_name = name\n",
    "                    best_params = params\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if best_name:\n",
    "            print(f\"  {symbol}: Best fit = {best_name} (AICc={best_aicc:.2f}), Params={np.round(best_params, 4)}\")\n",
    "            \n",
    "            # Ensure parameter structure is consistent, with loc=0 for relevant distributions\n",
    "            if best_name in ['Normal', 'SkewNorm']:\n",
    "                # For normal and skewnorm, ensure loc=0\n",
    "                params_list = list(best_params)\n",
    "                loc_idx = -2 if best_name == 'SkewNorm' else -1\n",
    "                params_list[loc_idx] = 0.0\n",
    "                best_params = tuple(params_list)\n",
    "            \n",
    "            best_fit_models[symbol] = {\n",
    "                'dist_name': best_name,\n",
    "                'params': best_params,\n",
    "                'dist_gen': dist_options[best_name]\n",
    "            }\n",
    "            fitting_results[symbol] = results_per_stock\n",
    "    \n",
    "    return best_fit_models, fitting_results\n",
    "\n",
    "# Fit distributions to each stock\n",
    "best_fit_models, fitting_results = fit_distributions(estimation_returns, all_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11c9a4aa-f9cd-4f3c-b5a4-7b8ea5a042d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Portfolio Definitions ---\n",
      "Portfolio A: 33 symbols, Value: $295444.61\n",
      "Portfolio B: 33 symbols, Value: $280904.48\n",
      "Portfolio C: 33 symbols, Value: $267591.44\n",
      "Portfolio Total: 99 symbols, Value: $843940.53\n"
     ]
    }
   ],
   "source": [
    "def create_ppf_cache(best_fit_models):\n",
    "    # Create lookup tables for faster simulation\n",
    "    ppf_cache = {}\n",
    "    quantile_points = 1000  # Number of points to precalculate\n",
    "    u_values = np.linspace(0.001, 0.999, quantile_points)\n",
    "\n",
    "    for symbol in best_fit_models:\n",
    "        model_info = best_fit_models[symbol]\n",
    "        dist_gen = model_info['dist_gen']\n",
    "        params = model_info['params']\n",
    "        ppf_values = dist_gen.ppf(u_values, *params)\n",
    "        ppf_cache[symbol] = {\n",
    "            'u_values': u_values,\n",
    "            'ppf_values': ppf_values\n",
    "        }\n",
    "    \n",
    "    return ppf_cache\n",
    "\n",
    "# Create PPF cache for faster simulation\n",
    "ppf_cache = create_ppf_cache(best_fit_models)\n",
    "\n",
    "def get_portfolio_definitions(initial_portfolio, prices, best_fit_models):\n",
    "    # Extract portfolio compositions and calculate weights\n",
    "    portfolio_ids = initial_portfolio['Portfolio'].unique()\n",
    "    portfolio_definitions = {}\n",
    "    initial_portfolio_weights = {}\n",
    "    portfolio_values = {}\n",
    "\n",
    "    # Use prices at the last day of the estimation period for initial weights\n",
    "    start_date_prices = prices.loc[prices.index <= '2023-12-31'].iloc[-1]\n",
    "\n",
    "    for pid in portfolio_ids:\n",
    "        df_sub = initial_portfolio[initial_portfolio['Portfolio'] == pid].copy()\n",
    "        df_sub = df_sub[df_sub['Symbol'].isin(best_fit_models.keys())]\n",
    "        symbols = df_sub['Symbol'].tolist()\n",
    "        shares = df_sub['Holding'].values\n",
    "\n",
    "        portfolio_definitions[str(pid)] = symbols\n",
    "\n",
    "        initial_market_values = []\n",
    "        valid_symbols_for_weight = []\n",
    "        \n",
    "        for symbol, share_val in zip(symbols, shares):\n",
    "            if symbol in start_date_prices.index and not pd.isna(start_date_prices[symbol]):\n",
    "                initial_market_values.append(share_val * start_date_prices[symbol])\n",
    "                valid_symbols_for_weight.append(symbol)\n",
    "\n",
    "        initial_market_values = np.array(initial_market_values)\n",
    "        initial_total_value = initial_market_values.sum()\n",
    "        portfolio_values[str(pid)] = initial_total_value\n",
    "\n",
    "        if np.isclose(initial_total_value, 0):\n",
    "            num_valid = len(valid_symbols_for_weight)\n",
    "            initial_weights = np.ones(num_valid) / num_valid if num_valid > 0 else np.array([])\n",
    "            print(f\"Warning: Portfolio {pid} initial value is zero. Assigning equal weights.\")\n",
    "        else:\n",
    "            initial_weights = initial_market_values / initial_total_value\n",
    "\n",
    "        initial_portfolio_weights[str(pid)] = pd.Series(initial_weights, index=valid_symbols_for_weight)\n",
    "        portfolio_definitions[str(pid)] = valid_symbols_for_weight\n",
    "    \n",
    "    # Create Total portfolio by aggregating all individual portfolios\n",
    "    # First, create a dataframe with all holdings\n",
    "    total_holdings = []\n",
    "    for pid in portfolio_ids:\n",
    "        df_sub = initial_portfolio[initial_portfolio['Portfolio'] == pid].copy()\n",
    "        total_holdings.append(df_sub)\n",
    "    \n",
    "    total_portfolio = pd.concat(total_holdings)\n",
    "    total_agg = total_portfolio.groupby('Symbol').sum().reset_index()\n",
    "    \n",
    "    # Filter symbols that have distribution models\n",
    "    total_symbols = [s for s in total_agg['Symbol'].tolist() if s in best_fit_models.keys()]\n",
    "    \n",
    "    # Calculate market values and weights for total portfolio\n",
    "    total_market_values = []\n",
    "    valid_total_symbols = []\n",
    "    \n",
    "    for symbol in total_symbols:\n",
    "        share_val = total_agg.loc[total_agg['Symbol'] == symbol, 'Holding'].values[0]\n",
    "        if symbol in start_date_prices.index and not pd.isna(start_date_prices[symbol]):\n",
    "            total_market_values.append(share_val * start_date_prices[symbol])\n",
    "            valid_total_symbols.append(symbol)\n",
    "    \n",
    "    total_market_values = np.array(total_market_values)\n",
    "    total_portfolio_value = total_market_values.sum()\n",
    "    portfolio_values['Total'] = total_portfolio_value\n",
    "    \n",
    "    if np.isclose(total_portfolio_value, 0):\n",
    "        num_valid = len(valid_total_symbols)\n",
    "        total_weights = np.ones(num_valid) / num_valid if num_valid > 0 else np.array([])\n",
    "        print(f\"Warning: Total portfolio initial value is zero. Assigning equal weights.\")\n",
    "    else:\n",
    "        total_weights = total_market_values / total_portfolio_value\n",
    "    \n",
    "    initial_portfolio_weights['Total'] = pd.Series(total_weights, index=valid_total_symbols)\n",
    "    portfolio_definitions['Total'] = valid_total_symbols\n",
    "    \n",
    "    print(f\"\\n--- Portfolio Definitions ---\")\n",
    "    for port_name, symbols in portfolio_definitions.items():\n",
    "        print(f\"Portfolio {port_name}: {len(symbols)} symbols, Value: ${portfolio_values[port_name]:.2f}\")\n",
    "    \n",
    "    return portfolio_definitions, initial_portfolio_weights, portfolio_values\n",
    "\n",
    "# Get portfolio definitions and weights\n",
    "portfolio_definitions, initial_portfolio_weights, portfolio_values = get_portfolio_definitions(\n",
    "    initial_portfolio, prices, best_fit_models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de16ccb2-2d06-46c4-9246-db53fe724267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_var_es(returns_sim, alpha):\n",
    "    # Calculate Value at Risk and Expected Shortfall\n",
    "    if len(returns_sim) == 0:\n",
    "        return np.nan, np.nan\n",
    "    sorted_returns = np.sort(returns_sim)\n",
    "    var_index = int(alpha * len(sorted_returns))\n",
    "    VaR = -sorted_returns[var_index]\n",
    "    ES = -np.mean(sorted_returns[:var_index+1])\n",
    "    return VaR, ES\n",
    "\n",
    "def run_gaussian_copula_simulation(symbols, weights, port_returns_est, best_fit_models, ppf_cache, n_simulations, alpha):\n",
    "    # Run Gaussian Copula simulation to estimate risk metrics\n",
    "    num_assets = len(symbols)\n",
    "    try:\n",
    "        # 1. Correlation Matrix (Spearman Rank Correlation)\n",
    "        spearman_corr = port_returns_est.corr(method='spearman').fillna(0).values\n",
    "        min_eig = np.min(np.linalg.eigh(spearman_corr)[0])\n",
    "        if min_eig <= 1e-12:\n",
    "            # Add small adjustment to ensure positive definiteness\n",
    "            spearman_corr += np.eye(num_assets) * 1e-10\n",
    "\n",
    "        # 2. Cholesky Decomposition\n",
    "        chol_decomp = np.linalg.cholesky(spearman_corr)\n",
    "\n",
    "        # 3. Simulate Standard Normal Variates\n",
    "        Z_standard_normal = np.random.randn(n_simulations, num_assets)\n",
    "\n",
    "        # 4. Correlate Variates\n",
    "        Z_correlated = Z_standard_normal @ chol_decomp.T\n",
    "\n",
    "        # 5. Transform to Uniform\n",
    "        U_simulated = stats.norm.cdf(Z_correlated)\n",
    "\n",
    "        # 6. Transform to Marginal Distributions (using cached PPF where available)\n",
    "        X_simulated = np.zeros_like(U_simulated)\n",
    "        for i, symbol in enumerate(symbols):\n",
    "            if symbol in ppf_cache:\n",
    "                # Fast interpolation from cached values\n",
    "                cache = ppf_cache[symbol]\n",
    "                X_simulated[:, i] = np.interp(U_simulated[:, i], \n",
    "                                           cache['u_values'], \n",
    "                                           cache['ppf_values'])\n",
    "            elif symbol in best_fit_models:\n",
    "                # Direct calculation if not cached\n",
    "                model_info = best_fit_models[symbol]\n",
    "                dist_gen = model_info['dist_gen']\n",
    "                params = model_info['params']\n",
    "                X_simulated[:, i] = dist_gen.ppf(U_simulated[:, i], *params)\n",
    "            else:\n",
    "                X_simulated[:, i] = stats.norm.ppf(U_simulated[:, i], loc=0, \n",
    "                                                scale=port_returns_est[symbol].std())\n",
    "\n",
    "        # Handle infinities or NaNs\n",
    "        X_simulated[np.isinf(X_simulated) | np.isnan(X_simulated)] = 0.0\n",
    "\n",
    "        # 7. Calculate Portfolio Returns\n",
    "        portfolio_returns_sim_copula = X_simulated @ weights\n",
    "\n",
    "        # 8. Calculate VaR/ES\n",
    "        VaR_copula, ES_copula = calculate_var_es(portfolio_returns_sim_copula, alpha)\n",
    "        \n",
    "        return VaR_copula, ES_copula, X_simulated\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Copula Error: {e}\")\n",
    "        return np.nan, np.nan, None\n",
    "\n",
    "def estimate_marginal_contribution_to_es(X_simulated, weights, ES_level, alpha):\n",
    "    # Calculate how much each asset contributes to portfolio risk\n",
    "    n_simulations, n_assets = X_simulated.shape\n",
    "    \n",
    "    # Calculate portfolio returns\n",
    "    portfolio_returns = X_simulated @ weights\n",
    "    \n",
    "    # Identify losses beyond VaR (tail events)\n",
    "    sorted_indices = np.argsort(portfolio_returns)\n",
    "    tail_indices = sorted_indices[:int(alpha * n_simulations)]\n",
    "    \n",
    "    # For each asset, calculate average return during tail events\n",
    "    marginal_contributions = np.zeros(n_assets)\n",
    "    for i in range(n_assets):\n",
    "        # Average contribution during tail events\n",
    "        marginal_contributions[i] = np.mean(X_simulated[tail_indices, i])\n",
    "    \n",
    "    # Scale by weights to get marginal contribution to ES\n",
    "    scaled_contributions = weights * marginal_contributions\n",
    "    \n",
    "    # Normalize to ensure they sum to ES\n",
    "    if np.sum(scaled_contributions) != 0:  # Avoid division by zero\n",
    "        scaled_contributions = scaled_contributions * (ES_level / np.sum(scaled_contributions))\n",
    "    \n",
    "    return scaled_contributions\n",
    "\n",
    "def risk_parity_objective(weights, X_simulated, alpha, target_risk_contribution=None):\n",
    "    # Objective function for risk parity optimization\n",
    "    weights = np.array(weights)\n",
    "    n_assets = len(weights)\n",
    "    \n",
    "    # Ensure weights sum to 1\n",
    "    weights = weights / np.sum(weights)\n",
    "    \n",
    "    # Calculate portfolio ES and marginal contributions\n",
    "    portfolio_returns = X_simulated @ weights\n",
    "    _, ES = calculate_var_es(portfolio_returns, alpha)\n",
    "    \n",
    "    if np.isnan(ES) or ES <= 0:\n",
    "        return 1e10  # Large penalty for invalid ES\n",
    "    \n",
    "    # Calculate marginal contributions to ES and percentage risk contributions\n",
    "    marginal_contributions = estimate_marginal_contribution_to_es(X_simulated, weights, ES, alpha)\n",
    "    percentage_contributions = marginal_contributions / ES\n",
    "    \n",
    "    if target_risk_contribution is None:\n",
    "        # Equal risk contribution target (1/n_assets)\n",
    "        target_risk_contribution = np.ones(n_assets) / n_assets\n",
    "    \n",
    "    # Calculate squared deviations from target\n",
    "    risk_concentration = np.sum((percentage_contributions - target_risk_contribution) ** 2)\n",
    "    \n",
    "    return risk_concentration\n",
    "\n",
    "def calculate_capm_parameters(portfolio_ids, df_portfolio, estimation_data, market_col, market_returns_est):\n",
    "    # Calculate CAPM parameters (alpha, beta) for each stock\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    results_capm_all = {}\n",
    "    \n",
    "    for pid in portfolio_ids:\n",
    "        df_sub = df_portfolio[df_portfolio[\"Portfolio\"] == pid]\n",
    "        symbols = df_sub[\"Symbol\"].tolist()\n",
    "        results_capm = {}\n",
    "        for sym in symbols:\n",
    "            if sym == market_col:\n",
    "                continue\n",
    "            y_i = estimation_data[sym] - estimation_data[\"rf\"]\n",
    "            x_m = market_returns_est\n",
    "            mask = (~y_i.isna()) & (~x_m.isna())\n",
    "            \n",
    "            if mask.sum() < 2:  # Skip if not enough data\n",
    "                results_capm[sym] = (0.0, 0.0)\n",
    "                continue\n",
    "                \n",
    "            x_ = x_m[mask].values.reshape(-1, 1)\n",
    "            y_ = y_i[mask].values\n",
    "            reg = LinearRegression().fit(x_, y_)\n",
    "            results_capm[sym] = (float(reg.intercept_), float(reg.coef_[0]))  # alpha, beta\n",
    "            \n",
    "        results_capm_all[str(pid)] = results_capm\n",
    "    \n",
    "    return results_capm_all\n",
    "\n",
    "# Calculate CAPM parameters for attribution\n",
    "portfolio_ids = initial_portfolio[\"Portfolio\"].unique()\n",
    "results_capm_all = calculate_capm_parameters(\n",
    "    portfolio_ids, initial_portfolio, estimation_data, market_col, market_returns_est\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daec0b3b-823c-4cc5-a1d1-f21fea5d7c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating Risk Parity Portfolios (Using ES as Risk Metric) ---\n",
      "\n",
      "Optimizing Risk Parity for Portfolio: A\n",
      "  Risk parity optimization successful: Optimization terminated successfully\n",
      "  Initial Portfolio: VaR=1.3729%, ES=1.8179%\n",
      "  Risk Parity Portfolio: VaR=1.2000%, ES=1.5834%\n",
      "  Top weight increases:\n",
      "    MRK: +2.78%\n",
      "    KO: +2.76%\n",
      "    PG: +2.74%\n",
      "  Top weight decreases:\n",
      "    BA: -2.88%\n",
      "    AMD: -2.23%\n",
      "    PLD: -2.04%\n",
      "\n",
      "Optimizing Risk Parity for Portfolio: B\n",
      "  Risk parity optimization successful: Optimization terminated successfully\n",
      "  Initial Portfolio: VaR=1.2757%, ES=1.6915%\n",
      "  Risk Parity Portfolio: VaR=1.1775%, ES=1.5646%\n",
      "  Top weight increases:\n",
      "    WMT: +3.93%\n",
      "    LLY: +1.62%\n",
      "    PGR: +1.21%\n",
      "  Top weight decreases:\n",
      "    ADBE: -3.16%\n",
      "    AMAT: -1.16%\n",
      "    DE: -0.97%\n",
      "\n",
      "Optimizing Risk Parity for Portfolio: C\n",
      "  Risk parity optimization successful: Optimization terminated successfully\n",
      "  Initial Portfolio: VaR=1.2898%, ES=1.7193%\n",
      "  Risk Parity Portfolio: VaR=1.1803%, ES=1.5749%\n",
      "  Top weight increases:\n",
      "    ABBV: +2.59%\n",
      "    IBM: +2.04%\n",
      "    BSX: +1.66%\n",
      "  Top weight decreases:\n",
      "    INTU: -2.01%\n",
      "    LRCX: -1.60%\n",
      "    UBER: -1.39%\n",
      "\n",
      "Optimizing Risk Parity for Portfolio: Total\n",
      "  Risk parity optimization successful: Optimization terminated successfully\n",
      "  Initial Portfolio: VaR=1.2821%, ES=1.7062%\n",
      "  Risk Parity Portfolio: VaR=1.1574%, ES=1.5419%\n",
      "  Top weight increases:\n",
      "    WMT: +1.29%\n",
      "    LLY: +0.87%\n",
      "    ABBV: +0.80%\n",
      "  Top weight decreases:\n",
      "    ADBE: -1.06%\n",
      "    BA: -1.03%\n",
      "    AMD: -0.80%\n",
      "\n",
      "Risk Parity Portfolio Summary:\n",
      "  Portfolio  Portfolio Value ($)  Initial ES (%)  Risk Parity ES (%)  \\\n",
      "0         A        295444.608200        1.817870            1.583382   \n",
      "1         B        280904.482409        1.691464            1.564644   \n",
      "2         C        267591.439955        1.719305            1.574859   \n",
      "3     Total        843940.530563        1.706247            1.541927   \n",
      "\n",
      "   ES Change (%)  \n",
      "0      -0.234489  \n",
      "1      -0.126820  \n",
      "2      -0.144446  \n",
      "3      -0.164321  \n"
     ]
    }
   ],
   "source": [
    "def create_risk_parity_portfolios(portfolio_definitions, initial_portfolio_weights, portfolio_values, \n",
    "                                 estimation_returns, best_fit_models, ppf_cache):\n",
    "    # Create risk-balanced portfolios for each sub-portfolio\n",
    "    print(f\"\\n--- Creating Risk Parity Portfolios (Using ES as Risk Metric) ---\")\n",
    "    \n",
    "    risk_parity_weights = {}\n",
    "    risk_parity_portfolio_info = []\n",
    "\n",
    "    for port_name, symbols in portfolio_definitions.items():\n",
    "        print(f\"\\nOptimizing Risk Parity for Portfolio: {port_name}\")\n",
    "        \n",
    "        if not symbols or len(symbols) < 2:\n",
    "            print(f\"  Skipping {port_name}: Not enough symbols for optimization.\")\n",
    "            if port_name in initial_portfolio_weights:\n",
    "                risk_parity_weights[port_name] = initial_portfolio_weights[port_name]\n",
    "            continue\n",
    "\n",
    "        port_returns_est = estimation_returns[symbols].dropna()\n",
    "        if port_returns_est.shape[0] < 10:  # Minimum data requirement\n",
    "            print(f\"  Skipping {port_name}: Not enough data points for optimization.\")\n",
    "            if port_name in initial_portfolio_weights:\n",
    "                risk_parity_weights[port_name] = initial_portfolio_weights[port_name]\n",
    "            continue\n",
    "\n",
    "        initial_weights = initial_portfolio_weights[port_name].reindex(symbols).fillna(0)\n",
    "        \n",
    "        # Run risk parity optimization\n",
    "        optimal_weights = optimize_risk_parity_portfolio(\n",
    "            symbols, port_returns_est, best_fit_models, ppf_cache, initial_weights\n",
    "        )\n",
    "        \n",
    "        # Store the optimized weights\n",
    "        risk_parity_weights[port_name] = pd.Series(optimal_weights, index=symbols)\n",
    "        \n",
    "        # Calculate VaR and ES for the optimized portfolio\n",
    "        VaR_opt, ES_opt, _ = run_gaussian_copula_simulation(\n",
    "            symbols, optimal_weights, port_returns_est, best_fit_models, ppf_cache, \n",
    "            N_SIMULATIONS, ALPHA\n",
    "        )\n",
    "        \n",
    "        # For comparison, calculate the same metrics with initial weights\n",
    "        VaR_init, ES_init, _ = run_gaussian_copula_simulation(\n",
    "            symbols, initial_weights.values, port_returns_est, best_fit_models, ppf_cache, \n",
    "            N_SIMULATIONS, ALPHA\n",
    "        )\n",
    "        \n",
    "        # Report results\n",
    "        port_value = portfolio_values[port_name]\n",
    "        print(f\"  Initial Portfolio: VaR={VaR_init*100:.4f}%, ES={ES_init*100:.4f}%\")\n",
    "        print(f\"  Risk Parity Portfolio: VaR={VaR_opt*100:.4f}%, ES={ES_opt*100:.4f}%\")\n",
    "        \n",
    "        # Calculate weight changes\n",
    "        weight_changes = {}\n",
    "        for symbol in symbols:\n",
    "            init_weight = initial_weights[symbol] if symbol in initial_weights else 0\n",
    "            opt_weight = risk_parity_weights[port_name][symbol] if symbol in risk_parity_weights[port_name].index else 0\n",
    "            weight_changes[symbol] = opt_weight - init_weight\n",
    "        \n",
    "        # Find top weight increases and decreases\n",
    "        sorted_changes = sorted(weight_changes.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_increases = sorted_changes[:3] if len(sorted_changes) > 3 else sorted_changes\n",
    "        top_decreases = sorted_changes[-3:] if len(sorted_changes) > 3 else []\n",
    "        \n",
    "        print(\"  Top weight increases:\")\n",
    "        for symbol, change in top_increases:\n",
    "            print(f\"    {symbol}: +{change*100:.2f}%\")\n",
    "        \n",
    "        if top_decreases:\n",
    "            print(\"  Top weight decreases:\")\n",
    "            for symbol, change in reversed(top_decreases):\n",
    "                print(f\"    {symbol}: {change*100:.2f}%\")\n",
    "        \n",
    "        # Store information for summary\n",
    "        risk_parity_portfolio_info.append({\n",
    "            'Portfolio': port_name,\n",
    "            'Portfolio Value ($)': port_value,\n",
    "            'Initial ES (%)': ES_init * 100 if not np.isnan(ES_init) else np.nan,\n",
    "            'Risk Parity ES (%)': ES_opt * 100 if not np.isnan(ES_opt) else np.nan,\n",
    "            'ES Change (%)': (ES_opt - ES_init) * 100 if not (np.isnan(ES_init) or np.isnan(ES_opt)) else np.nan\n",
    "        })\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    risk_parity_summary = pd.DataFrame(risk_parity_portfolio_info)\n",
    "    print(\"\\nRisk Parity Portfolio Summary:\")\n",
    "    print(risk_parity_summary)\n",
    "    \n",
    "    return risk_parity_weights, risk_parity_summary\n",
    "\n",
    "# Create risk parity portfolios\n",
    "risk_parity_weights, risk_parity_summary = create_risk_parity_portfolios(\n",
    "    portfolio_definitions, initial_portfolio_weights, portfolio_values, \n",
    "    estimation_returns, best_fit_models, ppf_cache\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c269ea88-77a4-45c3-aeab-907ad12f77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_portfolio_returns(portfolio_ids, df_portfolio, holding_data, last_price, portfolio_weights=None):\n",
    "    # Calculate daily returns and dynamic weights for portfolios\n",
    "    daily_weights_all = {}\n",
    "    port_returns_all = {}\n",
    "    \n",
    "    for pid in portfolio_ids:\n",
    "        pid_str = str(pid)\n",
    "        df_sub = df_portfolio[df_portfolio[\"Portfolio\"] == pid]\n",
    "        symbols = df_sub[\"Symbol\"].tolist()\n",
    "        \n",
    "        # Use provided weights if available, otherwise calculate from holdings\n",
    "        if portfolio_weights is not None and pid_str in portfolio_weights:\n",
    "            weights_series = portfolio_weights[pid_str]\n",
    "            # Ensure all symbols have weights, use 0 for missing\n",
    "            weights = np.array([weights_series.get(sym, 0.0) for sym in symbols])\n",
    "            # Normalize to ensure weights sum to 1\n",
    "            if np.sum(weights) > 0:\n",
    "                weights = weights / np.sum(weights)\n",
    "            else:\n",
    "                weights = np.ones(len(symbols)) / len(symbols) if len(symbols) > 0 else np.array([])\n",
    "        else:\n",
    "            # Calculate weights from holdings (original method)\n",
    "            shares = df_sub[\"Holding\"].values\n",
    "            # Calculate initial weights\n",
    "            market_vals = shares * last_price[symbols].values\n",
    "            total_val = market_vals.sum()\n",
    "            \n",
    "            if np.isclose(total_val, 0):\n",
    "                weights = np.ones(len(symbols)) / len(symbols) if len(symbols) > 0 else np.array([])\n",
    "            else:\n",
    "                weights = market_vals / total_val\n",
    "        \n",
    "        # Track dynamic weights and returns\n",
    "        last_weights = weights.copy()\n",
    "        port_returns = []\n",
    "        daily_weights = []\n",
    "        \n",
    "        for date in holding_data.index:\n",
    "            daily_ret = holding_data.loc[date, symbols].values\n",
    "            daily_ret[np.isnan(daily_ret)] = 0.0\n",
    "            \n",
    "            # Calculate portfolio return for the day\n",
    "            port_return = np.sum(last_weights * daily_ret)\n",
    "            port_returns.append(port_return)\n",
    "            daily_weights.append(last_weights.copy())\n",
    "            \n",
    "            # Update weights based on returns\n",
    "            current_values = last_weights * (1 + daily_ret)\n",
    "            total_value = np.sum(current_values)\n",
    "            last_weights = np.zeros(len(symbols)) if np.isclose(total_value, 0) else current_values / total_value\n",
    "        \n",
    "        # Store results\n",
    "        daily_weights_all[pid_str] = pd.DataFrame(daily_weights, columns=symbols, index=holding_data.index)\n",
    "        port_returns_all[pid_str] = pd.Series(port_returns, index=holding_data.index)\n",
    "    \n",
    "    # Add the Total portfolio (combination of all portfolios)\n",
    "    if \"Total\" in portfolio_weights:\n",
    "        total_symbols = portfolio_weights[\"Total\"].index.tolist()\n",
    "        total_weights = portfolio_weights[\"Total\"].values\n",
    "        \n",
    "        # Track dynamic weights and returns\n",
    "        last_total_weights = total_weights.copy()\n",
    "        total_port_returns = []\n",
    "        total_daily_weights = []\n",
    "        \n",
    "        for date in holding_data.index:\n",
    "            if all(sym in holding_data.columns for sym in total_symbols):\n",
    "                daily_ret = holding_data.loc[date, total_symbols].values\n",
    "                daily_ret[np.isnan(daily_ret)] = 0.0\n",
    "                \n",
    "                # Calculate portfolio return for the day\n",
    "                total_port_return = np.sum(last_total_weights * daily_ret)\n",
    "                total_port_returns.append(total_port_return)\n",
    "                total_daily_weights.append(last_total_weights.copy())\n",
    "                \n",
    "                # Update weights based on returns\n",
    "                current_values = last_total_weights * (1 + daily_ret)\n",
    "                total_current_value = np.sum(current_values)\n",
    "                last_total_weights = np.zeros(len(total_symbols)) if np.isclose(total_current_value, 0) else current_values / total_current_value\n",
    "            else:\n",
    "                # Skip this date if we don't have data for all symbols\n",
    "                total_port_returns.append(0.0)\n",
    "                total_daily_weights.append(last_total_weights.copy())\n",
    "        \n",
    "        # Store results for the total portfolio\n",
    "        daily_weights_all[\"Total\"] = pd.DataFrame(total_daily_weights, columns=total_symbols, index=holding_data.index)\n",
    "        port_returns_all[\"Total\"] = pd.Series(total_port_returns, index=holding_data.index)\n",
    "    \n",
    "    return daily_weights_all, port_returns_all\n",
    "\n",
    "# Calculate portfolio returns with risk parity weights\n",
    "daily_weights_rp, port_returns_rp = calculate_portfolio_returns(\n",
    "    portfolio_ids, initial_portfolio, holding_data, last_price, risk_parity_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddb948f2-8650-403e-95e6-dcc17ef687d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Portfolio A Attribution Summary =====\n",
      "Total Return        : 0.184307\n",
      "  Systematic Return : 0.168369\n",
      "  Idiosyncratic Ret.: 0.015938\n",
      "Total Risk          : 0.006405\n",
      "  Systematic Risk   : 0.006036\n",
      "  Idiosyncratic Risk: 0.000369\n",
      "\n",
      "===== Portfolio B Attribution Summary =====\n",
      "Total Return        : 0.261808\n",
      "  Systematic Return : 0.168911\n",
      "  Idiosyncratic Ret.: 0.092897\n",
      "Total Risk          : 0.006381\n",
      "  Systematic Risk   : 0.005509\n",
      "  Idiosyncratic Risk: 0.000872\n",
      "\n",
      "===== Portfolio C Attribution Summary =====\n",
      "Total Return        : 0.310418\n",
      "  Systematic Return : 0.180532\n",
      "  Idiosyncratic Ret.: 0.129886\n",
      "Total Risk          : 0.007284\n",
      "  Systematic Risk   : 0.006306\n",
      "  Idiosyncratic Risk: 0.000978\n",
      "\n",
      "===== Portfolio Total Attribution Summary =====\n",
      "Total Return        : 0.249214\n",
      "  Systematic Return : 0.171459\n",
      "  Idiosyncratic Ret.: 0.077755\n",
      "Total Risk          : 0.006373\n",
      "  Systematic Risk   : 0.006184\n",
      "  Idiosyncratic Risk: 0.000189\n"
     ]
    }
   ],
   "source": [
    "def perform_attribution_analysis(portfolio_ids, df_portfolio, holding_data, \n",
    "                              port_returns_all, daily_weights_all, \n",
    "                              results_capm_all, market_returns_hold):\n",
    "    # Break down returns and risk into market and idiosyncratic components\n",
    "    return_results = []\n",
    "    risk_results = []\n",
    "    \n",
    "    # Add 'Total' to portfolio_ids if it exists in port_returns_all\n",
    "    if \"Total\" in port_returns_all and \"Total\" not in [str(pid) for pid in portfolio_ids]:\n",
    "        portfolio_ids = list(portfolio_ids) + [\"Total\"]\n",
    "    \n",
    "    # --- per-portfolio loop ---\n",
    "    for pid in portfolio_ids:\n",
    "        pid_str = str(pid)\n",
    "        \n",
    "        if pid_str not in port_returns_all or pid_str not in daily_weights_all:\n",
    "            print(f\"Skipping portfolio {pid_str}: Data not available\")\n",
    "            continue\n",
    "        \n",
    "        if pid_str == \"Total\" and pid_str not in results_capm_all:\n",
    "            # Create a combined portfolio for Total if it doesn't exist\n",
    "            total_capm = {}\n",
    "            for sym in daily_weights_all[pid_str].columns:\n",
    "                # Find this symbol in any existing portfolio\n",
    "                found = False\n",
    "                for other_pid in results_capm_all:\n",
    "                    if sym in results_capm_all[other_pid]:\n",
    "                        total_capm[sym] = results_capm_all[other_pid][sym]\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    total_capm[sym] = (0.0, 0.0)  # Default alpha, beta\n",
    "            results_capm_all[pid_str] = total_capm\n",
    "            \n",
    "        try:\n",
    "            if pid_str == \"Total\":\n",
    "                symbols = daily_weights_all[pid_str].columns\n",
    "            else:\n",
    "                symbols = df_portfolio[df_portfolio[\"Portfolio\"]==pid][\"Symbol\"].tolist()\n",
    "            \n",
    "            port_returns = port_returns_all[pid_str]\n",
    "            daily_wts = daily_weights_all[pid_str]\n",
    "\n",
    "            # build series of systematic & idiosyncratic returns\n",
    "            port_sys = []\n",
    "            port_idio = []\n",
    "            for date in holding_data.index:\n",
    "                r_m_t = market_returns_hold.loc[date] if date in market_returns_hold.index else 0.0\n",
    "                \n",
    "                if date in daily_wts.index:\n",
    "                    w_t = daily_wts.loc[date].values\n",
    "                else:\n",
    "                    continue  # Skip dates without weight data\n",
    "\n",
    "                # β from your pre-computed CAPM results\n",
    "                betas = []\n",
    "                for sym in symbols:\n",
    "                    # Get beta for this symbol, default to 0 if not found\n",
    "                    if pid_str in results_capm_all and sym in results_capm_all[pid_str]:\n",
    "                        betas.append(results_capm_all[pid_str].get(sym, (0.0, 0.0))[1])\n",
    "                    else:\n",
    "                        betas.append(0.0)\n",
    "                \n",
    "                port_sys_t = np.dot(w_t, betas) * r_m_t\n",
    "\n",
    "                if date in port_returns.index:\n",
    "                    port_total_t = port_returns.loc[date]\n",
    "                    port_sys.append(port_sys_t)\n",
    "                    port_idio.append(port_total_t - port_sys_t)\n",
    "\n",
    "            port_sys = pd.Series(port_sys, index=port_returns.index)\n",
    "            port_idio = pd.Series(port_idio, index=port_returns.index)\n",
    "\n",
    "            # align and mask\n",
    "            mask = port_returns.notna() & port_sys.notna() & port_idio.notna()\n",
    "            p_tot = port_returns[mask]; p_sys = port_sys[mask]; p_idio = port_idio[mask]\n",
    "\n",
    "            # Carino attribution\n",
    "            total_return = (1+p_tot).prod() - 1\n",
    "            k = 1.0 if np.isclose(total_return, 0) else np.log1p(total_return)/total_return\n",
    "\n",
    "            k_t = pd.Series(1.0, index=p_tot.index)\n",
    "            nz = ~np.isclose(p_tot, 0)\n",
    "            k_t.loc[nz] = np.log1p(p_tot[nz])/(p_tot[nz]*k)\n",
    "\n",
    "            sys_ret = (p_sys * k_t).sum()\n",
    "            idio_ret = (p_idio * k_t).sum()\n",
    "\n",
    "            # risk attribution\n",
    "            total_vol = p_tot.std(ddof=0)\n",
    "            cov_sys = np.cov(p_sys, p_tot, ddof=0)[0,1] if len(p_tot)>1 else 0\n",
    "            cov_idio = np.cov(p_idio, p_tot, ddof=0)[0,1] if len(p_tot)>1 else 0\n",
    "\n",
    "            sys_risk = cov_sys/total_vol if total_vol and not np.isclose(total_vol, 0) else 0\n",
    "            idio_risk = cov_idio/total_vol if total_vol and not np.isclose(total_vol, 0) else 0\n",
    "\n",
    "            # print & store\n",
    "            print(f\"\\n===== Portfolio {pid_str} Attribution Summary =====\")\n",
    "            print(f\"Total Return        : {total_return:.6f}\")\n",
    "            print(f\"  Systematic Return : {sys_ret:.6f}\")\n",
    "            print(f\"  Idiosyncratic Ret.: {idio_ret:.6f}\")\n",
    "            print(f\"Total Risk          : {total_vol:.6f}\")\n",
    "            print(f\"  Systematic Risk   : {sys_risk:.6f}\")\n",
    "            print(f\"  Idiosyncratic Risk: {idio_risk:.6f}\")\n",
    "\n",
    "            return_results.append({\n",
    "                \"Portfolio\": pid_str,\n",
    "                \"Total Return\": total_return,\n",
    "                \"Systematic Return\": sys_ret,\n",
    "                \"Idiosyncratic Return\": idio_ret,\n",
    "                \"Systematic Return %\": sys_ret/total_return*100 if total_return != 0 else np.nan,\n",
    "                \"Idiosyncratic Return %\": idio_ret/total_return*100 if total_return != 0 else np.nan\n",
    "            })\n",
    "            \n",
    "            risk_results.append({\n",
    "                \"Portfolio\": pid_str,\n",
    "                \"Total Risk\": total_vol,\n",
    "                \"Systematic Risk\": sys_risk,\n",
    "                \"Idiosyncratic Risk\": idio_risk,\n",
    "                \"Systematic Risk %\": sys_risk/total_vol*100 if total_vol != 0 else np.nan,\n",
    "                \"Idiosyncratic Risk %\": idio_risk/total_vol*100 if total_vol != 0 else np.nan\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing portfolio {pid_str}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Final DataFrames\n",
    "    return_df = pd.DataFrame(return_results).round(6)\n",
    "    risk_df = pd.DataFrame(risk_results).round(6)\n",
    "    \n",
    "    return return_df, risk_df\n",
    "\n",
    "# Perform attribution analysis with risk parity weights\n",
    "return_df_rp, risk_df_rp = perform_attribution_analysis(\n",
    "    portfolio_ids, initial_portfolio, holding_data, \n",
    "    port_returns_rp, daily_weights_rp, \n",
    "    results_capm_all, market_returns_hold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be8e7e96-bd48-4a5b-83d6-cf4f748becf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "            RETURN ATTRIBUTION SUMMARY            \n",
      "==================================================\n",
      "Portfolio  Total Return  Systematic Return  Idiosyncratic Return  Systematic Return %  Idiosyncratic Return %\n",
      "        A      0.184307           0.168369              0.015938            91.352714                8.647286\n",
      "        B      0.261808           0.168911              0.092897            64.517228               35.482772\n",
      "        C      0.310418           0.180532              0.129886            58.157703               41.842297\n",
      "    Total      0.249214           0.171459              0.077755            68.799758               31.200242\n",
      "\n",
      "==================================================\n",
      "             RISK ATTRIBUTION SUMMARY             \n",
      "==================================================\n",
      "Portfolio  Total Risk  Systematic Risk  Idiosyncratic Risk  Systematic Risk %  Idiosyncratic Risk %\n",
      "        A    0.006405         0.006036            0.000369          94.232502              5.767498\n",
      "        B    0.006381         0.005509            0.000872          86.339441             13.660559\n",
      "        C    0.007284         0.006306            0.000978          86.572422             13.427578\n",
      "    Total    0.006373         0.006184            0.000189          97.031895              2.968105\n"
     ]
    }
   ],
   "source": [
    "# Display final results\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RETURN ATTRIBUTION SUMMARY\".center(50))\n",
    "print(\"=\" * 50)\n",
    "print(return_df_rp.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RISK ATTRIBUTION SUMMARY\".center(50))\n",
    "print(\"=\" * 50)\n",
    "print(risk_df_rp.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4489ab-6710-408f-a4b3-32a63973f32b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Jupyter Env)",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
